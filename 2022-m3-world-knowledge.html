<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>World Knowledge Priors</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <!-- 
https://www.m3-konferenz.de/veranstaltung-14113-0-wie-kann-man-weltwissen-ins-machine-learning-einbringen.html
3.6.2022: 10:15 - 11:00
45 Minuten

Wie kann man Weltwissen ins Machine Learning einbringen?

Machine-Learning-Modelle verfügen a priori nicht über allgemeines Weltwissen. Dieser Mangel lässt sie oft kläglich
scheitern, vor allem, wenn sie auf Bereiche extrapolieren, die nicht durch Trainingsdaten abgedeckt sind.

Es gibt viele Beispiele für Dinge, die wir Menschen wissen, aber einem ML-System erst einmal beigebracht werden müssen.
Dazu zählen bestimmte Invarianten in der Bilderkennung wie, z.B. die Tatsache, dass ein Objekt im Wesentlichen gleich
aussieht, egal wo es sich befindet. Weitere Beispiele sind das Wissen, dass kein Mensch über 150 Jahre alt ist und Autos
typischerweise nicht die Schallgeschwindigkeit erreichen.

Dieser Vortrag ist ein Überblick über bekannte Methoden, dieses Wissen in einen Machine-Learning-Prozess einzubringen:
die Wahl des richtigen Losses, die Erzwingung von Sparsity, die Wahl guter Dimensionen, Lattices, Arten von
Netzwerkschichten und – nicht zuletzt – augmentierte Trainingsdaten.
            -->

<section data-markdown>
    <textarea data-template>
## Wie kann man Weltwissen ins Machine Learning einbringen?                

M3 2022, https://www.m3-konferenz.de/veranstaltung-14113-0-wie-kann-man-weltwissen-ins-machine-learning-einbringen.html

Oliver Zeigermann / oliver.zeigermann@openknowledge.de


<!-- Folien: https://bit.ly/2022-oop-ml -->

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Wo ist der Schlumpf?

<video src="img/smurf/smurf-short.mp4" controls>

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
## Hier geht es nicht so sehr darum, ob dies ein großartiger Trick ist, sondern eher darum, dass...

* **Objektpermanenz** https://en.wikipedia.org/wiki/Object_permanence
* ein Wissen über die Welt ist, dessen wir uns so sicher sind
* dass wir gestresst werden, wenn es in Frage gestellt wird
* und denken sofort: Wo ist es hin?
* Grundlage für eine große Anzahl von Zaubertricks
        
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Weltwissen 

* Wir Menschen haben ein grundlegendes Verständnis von Weltwissen.
* sei es über die Physik normaler Objekte oder über die Eigenschaften von Menschen. 
* wir erwarten dies ebenso von einem intelligenten automatischen System
* erfüllt ein System dies nicht sind wir enttäuscht und unser Vertrauen in das System sinkt 

</textarea>
</section>


<section data-markdown>
### Themen

Grundlagen
* Encoding World Knowledge just applied statistics and mathematics?
* Einfache Priors
* Parametrische Modelle
* Regularisierung
* Augmentation

Fortgeschrittenes
* Markov-Ketten
* Kausalität
* Foundation Models
</section>

<section data-markdown>
## Einfache Priors    
</section>

<section data-markdown class="todo">
### Symbole und Suche

https://nautil.us/deep-learning-is-hitting-a-wall-14467/
</section>

<section data-markdown class="todo">
### Bayesian Models, Weltwissen ist Prior
</section>
        
<section data-markdown class="todo">

World Knowledge as 
* pre-processing, feature engineering
* post processing
</section>

<section data-markdown class="todo">
### Training Objective is part of world Knowledge

Well explained blog post about over-optimizing reward models using simple best-of-n sampling: https://t.co/O3ocQ49etY

By Jacob Hilton and @nabla_theta
(https://twitter.com/janleike/status/1514304430824300546?t=7PmXFiyCHY9615YgAdP3VQ&s=03) 
</section>

<section data-markdown>
    <textarea data-template>
### Case: Order

- https://raschka-research-group.github.io/coral-pytorch/
- Ok, aber die Tatsache dass man weiss dass da eine Ordnung ist ist vielleicht eine Art Prior. Aber das ist sehr weitgegriffen vielleicht
</textarea>
</section>

<section data-markdown class="todo">
### NN

* Auswirkung von
  * Geringerer Dimensionen 
  * Regularisierung
    * L1 and L2
* https://www.tensorflow.org/neural_structured_learning
</section>

<section data-markdown class="todo">
Learning Setting: Unsupervised, we know what is normal. Normal derives from being the majority of cases. But we assume normality.
</section>

<section data-markdown class="todo">
    <textarea data-template>
### RL

Indirektes Domainwissen in RL über Observation und Reward und Action Modellierung
</textarea>
</section>
    
<section data-markdown>
## Parametrische Modelle    
</section>

<section data-markdown class="todo">
### Parametric Solutions    

We assume certain properties of the model, like being normally distributed, and just learn the parameters of such properties, like mean and std.

</section>



<section data-markdown class="todo">
### World Knowledge in Parametric Models
    
Christoph Molnar (@ChristophMolnar) twitterte um 0:40 PM on So., März 27, 2022:
The modeling mindset of statisticians in one tweet

1) Measure random variables, e.g. water temperature
2) Assume distribution, e.g. Normal distribution
3) Goal: Find optimal distribution parameters, e.g. mean
4) Solution: Maximize the likelihood

Parameters = Insight about world https://t.co/vfpjA9sCfT
(https://twitter.com/ChristophMolnar/status/1508031278590873607?t=R2uQnLifwuc8MOPKGtyLPQ&s=03) 
</textarea>
</section>


<section data-markdown>
## Regularisierung    
</section>

<section data-markdown class="todo">
### Regularization as a way to add world knowledge

* L1 as Sparsity enforcing prior
  * Use L1 if you know your images only contain few pixels
* L2 enforcing small values as prior     
</section>


<section data-markdown class="todo">

Miles Cranmer (@MilesCranmer) twitterte um 11:54 PM on Sa., Apr. 16, 2022:
In a neural network, is there a type of  regularization which encourages one learned feature to be independent, **including nonlinearly,** of other features in the same layer?

I can’t use a bottleneck or sparsity constraint—I actually want to maximize the dimensionality!
(https://twitter.com/MilesCranmer/status/1515448502377234436?t=fFix03REi1KsQ64zcz8kVQ&s=03) 
</section>

    


<section data-markdown>
## Augmentation    
</section>
    
<section data-markdown class="todo">
https://lilianweng.github.io/posts/2022-04-15-data-gen/

</section>


<section data-markdown>
## Kausalität    
</section>

<section data-markdown class="todo">
### causality    

Dan Roberts (@danintheory) twitterte um 4:41 PM on So., Feb. 20, 2022:
I respectfully disagree w/ this and @ylecun's perspectives on causality: (a) causality is an essential part of microscopic physics and (b) even at the effective level of Newtonian physics, F=ma is *not* symmetric since it's a differential equation, not an algebraic equality.

1/
(https://twitter.com/danintheory/status/1495423336519770112?t=hbKV7pkdpDDK6oCgdNKktg&s=03) 
</section>


<section data-markdown class="todo">

* Die meisten Ansätze erzeugen Kandidaten und bewerten anhand von der Realität mit Scores oder Unabhängigkeitstests

Nan Rosemary Ke (@rosemary_ke) twitterte um 5:53 AM on Mi., Apr. 20, 2022:
Supervised causal induction: In this work, we learn to induce causal structure by
treating the inference process as a black box and design a neural network architecture
that learns the mapping from data to graph
structures via supervised training.https://t.co/fHVQlkJLxg https://t.co/dsBvaU2kbe
(https://twitter.com/rosemary_ke/status/1516626111182028803?t=ZG3F-ReQmn7c1fbODdM8dg&s=03)
</section>


<section data-markdown>
## Markov-Ketten
</section>

<section data-markdown class="todo">
### Markov Chains as Matrices

Tivadar Danka 🇺🇦 (@TivadarDanka) twitterte um 10:30 AM on Fr., März 11, 2022:
The single most undervalued fact of linear algebra: matrices are graphs, and graphs are matrices.

Encoding matrices as graphs is a cheat code, making complex behavior simple to study.

Let me show you how! https://t.co/8rBIkA8ZbZ
(https://twitter.com/TivadarDanka/status/1502215264544296962?t=gMcg-3niXfPHyXfw4wx8_g&s=03) 

</section>

<section data-markdown>
## Foundation Models
</section>

<section data-markdown class="todo">
    <textarea data-template>
Foundation Models versprechen das Wissen über die Welt in Textform zu speichern            
    </textarea>
</section>


        </div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>
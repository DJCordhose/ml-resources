<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>World Knowledge Priors</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <!-- 
https://www.m3-konferenz.de/veranstaltung-14113-0-wie-kann-man-weltwissen-ins-machine-learning-einbringen.html
3.6.2022: 10:15 - 11:00
45 Minuten

Wie kann man Weltwissen ins Machine Learning einbringen?

Machine-Learning-Modelle verf√ºgen a priori nicht √ºber allgemeines Weltwissen. Dieser Mangel l√§sst sie oft kl√§glich
scheitern, vor allem, wenn sie auf Bereiche extrapolieren, die nicht durch Trainingsdaten abgedeckt sind.

Es gibt viele Beispiele f√ºr Dinge, die wir Menschen wissen, aber einem ML-System erst einmal beigebracht werden m√ºssen.
Dazu z√§hlen bestimmte Invarianten in der Bilderkennung wie, z.B. die Tatsache, dass ein Objekt im Wesentlichen gleich
aussieht, egal wo es sich befindet. Weitere Beispiele sind das Wissen, dass kein Mensch √ºber 150 Jahre alt ist und Autos
typischerweise nicht die Schallgeschwindigkeit erreichen.

Dieser Vortrag ist ein √úberblick √ºber bekannte Methoden, dieses Wissen in einen Machine-Learning-Prozess einzubringen:
die Wahl des richtigen Losses, die Erzwingung von Sparsity, die Wahl guter Dimensionen, Lattices, Arten von
Netzwerkschichten und ‚Äì nicht zuletzt ‚Äì augmentierte Trainingsdaten.
            -->

<section data-markdown>
    <textarea data-template>
## Wie kann man Weltwissen ins Machine Learning einbringen?                

M3 2022, https://www.m3-konferenz.de/veranstaltung-14113-0-wie-kann-man-weltwissen-ins-machine-learning-einbringen.html

Oliver Zeigermann / oliver.zeigermann@openknowledge.de


<!-- Folien: https://bit.ly/2022-oop-ml -->

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Wo ist der Schlumpf?

<video src="img/smurf/smurf-short.mp4" controls>

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
## Hier geht es nicht so sehr darum, ob dies ein gro√üartiger Trick ist, sondern eher darum, dass...

* **Objektpermanenz** https://en.wikipedia.org/wiki/Object_permanence
* ein Wissen √ºber die Welt ist, dessen wir uns so sicher sind
* dass wir gestresst werden, wenn es in Frage gestellt wird
* und denken sofort: Wo ist es hin?
* Grundlage f√ºr eine gro√üe Anzahl von Zaubertricks
        
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Weltwissen 

* Wir Menschen haben ein grundlegendes Verst√§ndnis von Weltwissen.
* sei es √ºber die Physik normaler Objekte oder √ºber die Eigenschaften von Menschen. 
* wir erwarten dies ebenso von einem intelligenten automatischen System
* erf√ºllt ein System dies nicht sind wir entt√§uscht und unser Vertrauen in das System sinkt 

</textarea>
</section>


<section data-markdown>
### Themen

Grundlagen
* Encoding World Knowledge just applied statistics and mathematics?
* Einfache Priors
* Parametrische Modelle
* Regularisierung
* Augmentation

Fortgeschrittenes
* Markov-Ketten
* Kausalit√§t
* Foundation Models
</section>

<section data-markdown>
## Einfache Priors    
</section>

<section data-markdown class="todo">
### Symbole und Suche

https://nautil.us/deep-learning-is-hitting-a-wall-14467/
</section>

<section data-markdown class="todo">
### Bayesian Models, Weltwissen ist Prior
</section>
        
<section data-markdown class="todo">

World Knowledge as 
* pre-processing, feature engineering
* post processing
</section>

<section data-markdown class="todo">
### Training Objective is part of world Knowledge

Well explained blog post about over-optimizing reward models using simple best-of-n sampling: https://t.co/O3ocQ49etY

By Jacob Hilton and @nabla_theta
(https://twitter.com/janleike/status/1514304430824300546?t=7PmXFiyCHY9615YgAdP3VQ&s=03) 
</section>

<section data-markdown>
    <textarea data-template>
### Case: Order

- https://raschka-research-group.github.io/coral-pytorch/
- Ok, aber die Tatsache dass man weiss dass da eine Ordnung ist ist vielleicht eine Art Prior. Aber das ist sehr weitgegriffen vielleicht
</textarea>
</section>

<section data-markdown class="todo">
### NN

* Auswirkung von
  * Geringerer Dimensionen 
  * Regularisierung
    * L1 and L2
* https://www.tensorflow.org/neural_structured_learning
</section>

<section data-markdown class="todo">
Learning Setting: Unsupervised, we know what is normal. Normal derives from being the majority of cases. But we assume normality.
</section>

<section data-markdown class="todo">
    <textarea data-template>
### RL

Indirektes Domainwissen in RL √ºber Observation und Reward und Action Modellierung
</textarea>
</section>
    
<section data-markdown>
## Parametrische Modelle    
</section>

<section data-markdown class="todo">
### Parametric Solutions    

We assume certain properties of the model, like being normally distributed, and just learn the parameters of such properties, like mean and std.

</section>



<section data-markdown class="todo">
### World Knowledge in Parametric Models
    
Christoph Molnar (@ChristophMolnar) twitterte um 0:40 PM on So., M√§rz 27, 2022:
The modeling mindset of statisticians in one tweet

1) Measure random variables, e.g. water temperature
2) Assume distribution, e.g. Normal distribution
3) Goal: Find optimal distribution parameters, e.g. mean
4) Solution: Maximize the likelihood

Parameters = Insight about world https://t.co/vfpjA9sCfT
(https://twitter.com/ChristophMolnar/status/1508031278590873607?t=R2uQnLifwuc8MOPKGtyLPQ&s=03) 
</textarea>
</section>


<section data-markdown>
## Regularisierung    
</section>

<section data-markdown class="todo">
### Regularization as a way to add world knowledge

* L1 as Sparsity enforcing prior
  * Use L1 if you know your images only contain few pixels
* L2 enforcing small values as prior     
</section>


<section data-markdown class="todo">

Miles Cranmer (@MilesCranmer) twitterte um 11:54 PM on Sa., Apr. 16, 2022:
In a neural network, is there a type of  regularization which encourages one learned feature to be independent, **including nonlinearly,** of other features in the same layer?

I can‚Äôt use a bottleneck or sparsity constraint‚ÄîI actually want to maximize the dimensionality!
(https://twitter.com/MilesCranmer/status/1515448502377234436?t=fFix03REi1KsQ64zcz8kVQ&s=03) 
</section>

    


<section data-markdown>
## Augmentation    
</section>
    
<section data-markdown class="todo">
https://lilianweng.github.io/posts/2022-04-15-data-gen/

</section>


<section data-markdown>
## Kausalit√§t    
</section>

<section data-markdown class="todo">
### causality    

Dan Roberts (@danintheory) twitterte um 4:41 PM on So., Feb. 20, 2022:
I respectfully disagree w/ this and @ylecun's perspectives on causality: (a) causality is an essential part of microscopic physics and (b) even at the effective level of Newtonian physics, F=ma is *not* symmetric since it's a differential equation, not an algebraic equality.

1/
(https://twitter.com/danintheory/status/1495423336519770112?t=hbKV7pkdpDDK6oCgdNKktg&s=03) 
</section>


<section data-markdown class="todo">

* Die meisten Ans√§tze erzeugen Kandidaten und bewerten anhand von der Realit√§t mit Scores oder Unabh√§ngigkeitstests

Nan Rosemary Ke (@rosemary_ke) twitterte um 5:53 AM on Mi., Apr. 20, 2022:
Supervised causal induction: In this work, we learn to induce causal structure by
treating the inference process as a black box and design a neural network architecture
that learns the mapping from data to graph
structures via supervised training.https://t.co/fHVQlkJLxg https://t.co/dsBvaU2kbe
(https://twitter.com/rosemary_ke/status/1516626111182028803?t=ZG3F-ReQmn7c1fbODdM8dg&s=03)
</section>


<section data-markdown>
## Markov-Ketten
</section>

<section data-markdown class="todo">
### Markov Chains as Matrices

Tivadar Danka üá∫üá¶ (@TivadarDanka) twitterte um 10:30 AM on Fr., M√§rz 11, 2022:
The single most undervalued fact of linear algebra: matrices are graphs, and graphs are matrices.

Encoding matrices as graphs is a cheat code, making complex behavior simple to study.

Let me show you how! https://t.co/8rBIkA8ZbZ
(https://twitter.com/TivadarDanka/status/1502215264544296962?t=gMcg-3niXfPHyXfw4wx8_g&s=03) 

</section>

<section data-markdown>
## Foundation Models
</section>

<section data-markdown class="todo">
    <textarea data-template>
Foundation Models versprechen das Wissen √ºber die Welt in Textform zu speichern            
    </textarea>
</section>


        </div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>
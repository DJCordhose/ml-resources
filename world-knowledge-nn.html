<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>World Knowledge Priors</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

<!-- Title: How to teach our world knowledge to a neural network?

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to become much more robust and even to extrapolate. But how do we encode this?

This talk is a survey on known methods including choosing the right loss, forcing sparsity, choose good dimensions, lattices, types of network layers, and - last but not least - augmented training data. 

There will also be a critique of too much trust in auto tuning libraries. They might win you a Kaggle competition, but might spoil your real-world applicability.

I will show actual code on different examples and share the code for you to take home as a starting point.

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though), but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the world knowledge you have.

Pitch: Deep Learning models are notorious for not being able to extrapolate from their area of training data. However, by encoding your world knowledge as priors you can at least push it in the right direction. It might even be the most important skill of a deep learning engineer to know how to do that.

Workshop:

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to become much more robust and even to extrapolate. But how do we encode this?

Based on code examples we will go through the known methods including choosing the right loss, forcing sparsity, choose good dimensions, lattices, types of network layers, and - last but not least - augmented training data. 

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though), but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the world knowledge you have.


Format: Workshop oder Talk

Level: Intermediate

Konferenzen:
-  ODSC Europe / West: https://odsc.com/europe/call-for-speakers-europe/
- M3
- Scipy

Inhalte:
- Data Augmentation using world knowledge
  - might explode with dimensions
  - augmented data might outweight "real" data 
- Sparsity
- CNN
- RNN
- Lattice
- Losses (xent vs mse)
- Why auto tuning might not be such a good idea (overfits on val data), but real priors might not even be obeyed
- Beispiel mit Lattice, Extrapolation und Tweet von Fchollet
- Daten-Beispiele selbst gemalte Bilder oder Sinus -->


            <section data-markdown>
                <textarea data-template>
# World Knowledge Priors

    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Links

* Why Do Better Loss Functions Lead to Less Transferable Features?" https://twitter.com/skornblith/status/1469132061579620355
* Implicit inference of 3D vision: This short paper in the journal i-Perception presents a disconcerting visual illusion spotted “in the wild”: how stackable chairs, viewed from a certain angle, mess with your head [read more, paper: https://t.co/ppu9j0pyIs] https://t.co/r2Sdie3UdF
(https://twitter.com/Rainmaker1973/status/1489209455489212416?t=gxzQxv4J1yKQWVNnVkQ6bA&s=03) 
    </textarea>
            </section>
            

        </div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>

    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

</body>

</html>
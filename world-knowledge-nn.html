<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>World Knowledge Priors</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <!-- 
Welt- und Domänenwissen für neuronalen Netze
 
Neuronale Netze können jede Funktion approximieren, sie haben jedoch nicht die geringste Ahnung von allgemeinem Wissen über die Welt. 
Dieser Mangel lässt sie oft kläglich scheitern, insbesondere bei der Extrapolation in Bereiche, die nicht durch Trainingsdaten abgedeckt sind.
 
Wir Menschen verfügen über dieses Welt- und Domänenwissen, das Deep-Learning-Modelle viel robuster werden lassen und sogar
Extrapolation erlauben könnte. Zum Beispiel lösen sich Objekte bei der Bilderkennung meistens nicht einfach in Luft auf und es gibt die Tendenz, dass Menschen mit zunehmendem Alter erst schneller, aber dann langsamer werden und irgendwann auch sterben. Nur, wie kodieren wir dieses Wissen?
 
Dieser Vortrag ist ein Überblick über bekannte Methoden, einschließlich der Wahl des richtigen Losses, der Erzwingung von Sparsity,
der Wahl guter Dimensionen, Lattices, Arten von Netzwerkschichten und - nicht zuletzt - augmentierte Trainingsdaten.
 
M3 700 Zeichen kurzverversion:

Neuronale Netze können jede Funktion approximieren, sie haben jedoch nicht die geringste Ahnung von allgemeinem Wissen über die Welt. 

 
Dieser Vortrag ist ein Überblick über bekannte Methoden, einschließlich der Wahl des richtigen Losses, der Erzwingung von Sparsity,
der Wahl guter Dimensionen, Lattices, Arten von Netzwerkschichten und - nicht zuletzt - augmentierte Trainingsdaten.

Vorkenntnisse:

Ein grundsätzliches Verständnis wie neuronale Netze trainiert werden und Vorhersagen machen.

Lernziele:

Teilnehmer bekommen eine Idee von der Herausforderung Weltwissen in einen Trainingsprozess einfließen zu lassen und einen Überblick über die existierenden Möglichkeiten.
 
Neuer Abstract M3

Wie kann man Weltwissen ins Machine Learning einbringen?

Machine Learning Modelle verfügen a priori nicht über allgemeines Weltwissen. 
Dieser Mangel lässt sie oft kläglich scheitern, vor allem, wenn sie auf Bereiche extrapolieren, die nicht durch Trainingsdaten abgedeckt sind. 

Wir Menschen verfügen über dieses Welt- und Domänenwissen, das Machine Learning Modelle viel robuster werden lassen und sogar
Extrapolation erlauben könnte. So sind z.B. Objekte in der Bilderkennung häufig invariant zu einer bestimmten Reihe von Parametern, 
wie zum Beispiel der Position im Raum, oder man weiß, dass niemand über 150 Jahre alt ist oder Autos typischerweise nicht die Schallgeschwindigkeit erreichen.

Dieser Vortrag ist ein Überblick über bekannte Methoden, dieses wissen in einen Machine Learning Prozess einzubringen. 



-->
<!-- 

Pydata London:

Teaching world knowledge to a machine learning model

Abstract

Machine learning models do not have a priori general knowledge of the world. 
This lack often causes them to fail miserably, especially when they extrapolate to domains not covered by training data. 

We humans have this world and domain knowledge that could make machine learning models much more robust and even allow for extrapolation. 

Give give some examples: Objects in image recognition are often invariant to their relative position. 
It is known that human is over 150 years old. Cars typically do not reach the speed of sound. 

This talk is an overview of known methods to incorporate this knowledge into a machine learning process. 

Description

We will have general overview and focus a bit more on neural networks.
Topics will include: data augmentation, Bayesian priors, parametric vs non-parametric models, regularization, Markov chains, and more.

You will need a basic understanding of how machine learning works, but no knowledge about libraries, as this talk will be more conceptual than code driven. 
 -->

            <!-- Title: How to teach our world knowledge to a neural network?

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to become much more robust and even to extrapolate. But how do we encode this?

This talk is a survey on known methods including choosing the right loss, forcing sparsity, choose good dimensions, lattices, types of network layers, and - last but not least - augmented training data. 

There will also be a critique of too much trust in auto tuning libraries. They might win you a Kaggle competition, but might spoil your real-world applicability.

I will show actual code on different examples and share the code for you to take home as a starting point.

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though), but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the world knowledge you have.

Pitch: Deep Learning models are notorious for not being able to extrapolate from their area of training data. However, by encoding your world knowledge as priors you can at least push it in the right direction. It might even be the most important skill of a deep learning engineer to know how to do that.

Workshop:

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common
knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by
training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to
become much more robust and even to extrapolate. But how do we encode this?

Based on code examples we will go through the known methods including choosing the right loss, forcing sparsity, choose
good dimensions, lattices, types of network layers, and - last but not least - augmented training data.

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though),
but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the
world knowledge you have.


Format: Workshop oder Talk

Level: Intermediate

Konferenzen:
-  ODSC Europe / West: https://odsc.com/europe/call-for-speakers-europe/
- M3
- Scipy

Inhalte:
- GenerelL: Pre oder Post Processing kodiert oder dekodiert Weltwissen
- Data Augmentation using world knowledge
  - might explode with dimensions
  - augmented data might outweight "real" data 
- Sparsity
- CNN
- RNN
- Lattice
- Losses (xent vs mse)
- Why auto tuning might not be such a good idea (overfits on val data), but real priors might not even be obeyed
- Beispiel mit Lattice, Extrapolation und Tweet von Fchollet
- Daten-Beispiele selbst gemalte Bilder oder Sinus
- Hidden Markov Models
  * https://en.wikipedia.org/wiki/Markov_chain
- Kalman Filter
  * https://en.wikipedia.org/wiki/Kalman_filter

Weltwissen hauptsächlich Frage der Architektur
- Traditionelle Systeme instrumentieren viele kleine Modelle als Pattern matcher viel besser als
- Großes System als Blackbox

Großes System als Blackbox
Eigener Talk
- die wichtigste Architektur Frage im Machine Learning
- Ein großes Modell oder viele kleine traditionell instrumentiert

---

Talk: ODSC Europe

Why you should prefer many small models over a single large one

When designing a solution using machine learning one of the central architectural questions is whether you
should use a set of small models orchestrated by traditional code or a single big one that just figures out
things from beginning to end.

In this talk I take the standpoint that a single large one should be avoided for many reasons. The main
reason for choosing small ones is to keep being in control as the human domain expert. This applies to
training as well as putting in domain knowledge your models can not possibly have.

While this might also be of interest in the academic world in context of whether deep learning is the
solution to all in this talk we will look at it from a practical perspective.

Of course this is an over-generalization, but I found this to be true in all the projects I have
participated in and in many other common ones.


---

Talk: QCon

Title: The most important architectural decision in machine learning: many small models over a single large one?

actionable takeaways

What are the most important architectural questions in machine learning? 
Why architecture for machine learning has a special place in the world of software engineering. 
Among the important decisions you need to make early which are the ones that are especially hard to change. 
Why such a seemingly harmless question has so much emotional potential.

While sounding harmless at first sight, there is also a lot of emotional potential in this question.




what is by far the most important and hardly correctable architectural decision in retrospect

As another teaser: doesn't look important at first, and requires much explanation why it is so

---

Scipy Updated und genereller

How to bring world knowledge into a machine learning model?

Machine learning models in general and neural networks in particular do not have common knowledge of the world a priori.
This lack often makes them fail miserably, especially when extrapolating to areas not covered by training data.

We, as human beings have knowledge about the world and our domains of expertise, that would allow machine learning
models to become much more robust and even to extrapolate. But how do we encode this?

This talk is a survey of known methods that tackle the issue from different angles. We will look at baking knowledge
into deep neural networks as well as combining machine learning models with well known classic AI techniques. Techniques
include Markov chains, rule systems, and augmented training data for approaches from the outside and choosing the right
loss, forcing sparsity, good dimensions, lattices, and types of network layers for bringing a prior into neural
networks.
-->




<section data-markdown>
    <textarea data-template>
### Where did the Smurf go?

<video src="img/smurf/smurf-short.mp4" controls>

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
## This isn't so much about whether this is a great trick, but rather...

* **object permanence** https://en.wikipedia.org/wiki/Object_permanence
* is a knowledge about the world we are so certain of
* we get stressed when it is challenged
* and immediately start thinking: where did it go?
* basis for a large number of magical tricks

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Did it go here?

<img src="img/smurf/smurf-fallen.jpg">

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### No, it is really gone

<video src="img/smurf/smurf-full.mp4" controls>


</textarea>
</section>


            <section data-markdown>
                <textarea data-template>
# World Knowledge Priors

    </textarea>
            </section>

<section data-markdown class="todo">
### Augmentation

Comic auf (unterschiedliche) echte Hintergrund als Weltwissen

</section>


<section data-markdown class="todo">
### Bayesian Model, Weltwissen ist Prior
</section>

            <section data-markdown class="todo">
### Fancy stuff, including AlphaZero

Gary Marcus (@GaryMarcus) twitterte um 2:39 AM on Do., März 10, 2022:
Deep Learning Is Hitting a Wall. What would it take for artificial intelligence to make real progress?

#longread in ⁦@NautilusMag⁩ on one of the key technical questions in AI. https://t.co/ze8DtZuHwR
(https://twitter.com/GaryMarcus/status/1501734523628707845?t=wrMHHutT-voIXJ7HJ96HlA&s=03) 
        </textarea>
    </section>

<section data-markdown class="todo">
### Markov Chains as Matrices

Tivadar Danka 🇺🇦 (@TivadarDanka) twitterte um 10:30 AM on Fr., März 11, 2022:
The single most undervalued fact of linear algebra: matrices are graphs, and graphs are matrices.

Encoding matrices as graphs is a cheat code, making complex behavior simple to study.

Let me show you how! https://t.co/8rBIkA8ZbZ
(https://twitter.com/TivadarDanka/status/1502215264544296962?t=gMcg-3niXfPHyXfw4wx8_g&s=03) 

</section>

<section data-markdown class="todo">
### Parametric Solutions    

We assume certain properties of the model, like being normally distributed, and just learn the parameters of such properties, like mean and std.

</section>


<section data-markdown class="todo">
### causality    

Dan Roberts (@danintheory) twitterte um 4:41 PM on So., Feb. 20, 2022:
I respectfully disagree w/ this and @ylecun's perspectives on causality: (a) causality is an essential part of microscopic physics and (b) even at the effective level of Newtonian physics, F=ma is *not* symmetric since it's a differential equation, not an algebraic equality.

1/
(https://twitter.com/danintheory/status/1495423336519770112?t=hbKV7pkdpDDK6oCgdNKktg&s=03) 
</section>

<section data-markdown class="todo">

https://www.heise.de/hintergrund/Missing-Link-Was-wir-ueber-die-Fairness-der-Welt-von-moderner-KI-lernen-koennen-6351026.html
</section>
             
            <section data-markdown class="todo">
                <textarea data-template>
### What can we expect from modern AI?

Amanda Askell (@AmandaAskell) twitterte um 5:55 AM on Mo., Feb. 14, 2022:
Phenomenal consciousness = Does it have an inner cinema?
Self-consciousness = Is it aware of itself?
Sentience = Can it have positive or negative experiences?
Moral patienthood = Should we care about what we do to it?
Moral agency = Should we hold it accountable for what it does?
(https://twitter.com/AmandaAskell/status/1493086389549862915?t=T42_Nd0Vx-qxzuugx34GRg&s=03) 
        </textarea>
    </section>

<section data-markdown class="todo">
# consciousness

* Andy Jones (@andy_l_jones) twitterte um 0:05 AM on Di., Feb. 22, 2022:
    you can expect to see me repeating these very good opinions as my own
    (https://twitter.com/andy_l_jones/status/1495897492831227908?t=AOkHCeN0OUOXv2w4sf7vIQ&s=03)
* https://www.heise.de/hintergrund/Hat-KI-bereits-eine-Art-Bewusstsein-entwickelt-Forscher-streiten-darueber-6522868.html         
</section>


    <section data-markdown class="todo">
        <textarea data-template>
### Im Anschluss daran auch über Foundation Models sprechen            
        </textarea>
    </section>

            
            <section data-markdown class="todo">
                <textarea data-template>
### RL

Indirektes Domainwissen in RL über Observation und Reward und Action Modellierung
        </textarea>
    </section>

            <section data-markdown>
                <textarea data-template>
### Case: Order

- https://raschka-research-group.github.io/coral-pytorch/
- Ok, aber die Tatsache dass man weiss dass da eine Ordnung ist ist vielleicht eine Art Prior. Aber das ist sehr weitgegriffen vielleicht
        </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Links

* Why Do Better Loss Functions Lead to Less Transferable Features?" https://twitter.com/skornblith/status/1469132061579620355
* Implicit inference of 3D vision: This short paper in the journal i-Perception presents a disconcerting visual illusion spotted “in the wild”: how stackable chairs, viewed from a certain angle, mess with your head [read more, paper: https://t.co/ppu9j0pyIs] https://t.co/r2Sdie3UdF
(https://twitter.com/Rainmaker1973/status/1489209455489212416?t=gxzQxv4J1yKQWVNnVkQ6bA&s=03)
* What I’ve learned about making synthetic data work for training ML models: (https://twitter.com/russelljkaplan/status/1490303023267999744?t=QHQ_IkP8zs8LEzzr6bWmQQ&s=03)  
    </textarea>
            </section>


        </div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>
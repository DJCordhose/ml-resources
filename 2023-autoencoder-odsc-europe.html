<!doctype html>
<html lang="de">

<head>
    <meta charset="utf-8">

    <title>Autoencoders - a magical approach to unsupervised machine learning</title>

    <meta name="description" content="Autoencoders for Anomaly Detection">
    <meta name="author" content="Oliver Zeigermann">
	<link rel="shortcut icon" href="/img/favicon.ico" >

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
	<link rel="stylesheet" href="reveal.js/dist/theme/white.css">

	<!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
	<style>
		.right-img {
			margin-left: 10px !important;
			float: right;
			height: 500px;
		}

		.todo:before {
			content: 'TODO: ';
		}

		.todo {
			color: red !important;
		}

		code span.line-number {
			color: lightcoral;
		}

		.reveal pre code {
			max-height: 1000px !important;
		}

		img {
			border: 0 !important;
			box-shadow: 0 0 0 0 !important;
			height: 450px;
		}

		.reveal {
			-ms-touch-action: auto !important;
			touch-action: auto !important;
		}

		.reveal h1,
		.reveal h2,
		.reveal h3,
		.reveal h4 {
			/* letter-spacing: 2px; */
			font-family: 'Calibri', sans-serif;
			/* font-family: 'Times New Roman', Times, serif; */
			/* font-weight: bold; */
			color: black;
			/* font-style: italic; */
			/* letter-spacing: -2px; */
			text-transform: none !important;
		}

		.reveal em {
			font-weight: bold;
		}

		.reveal section img {
			background: none;
		}

		.reveal img.with-border {
			border: 1px solid #586e75 !important;
			box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
		}

		.reveal li {
			margin-bottom: 8px;
		}

		/* For li's that use FontAwesome icons as bullet-point */
		.reveal ul.fa-ul li {
			list-style-type: none;
		}

		.reveal {
			/* font-family: 'Work Sans', 'Calibri'; */
			font-family: 'Calibri';
			color: black !important;
			font-size: xx-large;
		}

		.container {
			display: flex;
		}

		.col img {
			height: auto;
		}

		.col,
		col-1 {
			flex: 1;
		}

		.col-2 {
			flex: 2;
		}

	/* https://intranet.openknowledge.de/plugins/servlet/mobile?contentId=18612939#content/view/18612939
      https://intranet.openknowledge.de/pages/viewpage.action?pageId=16157867
      https://openknowledgede.sharepoint.com/:p:/s/slides/EYWbMPz2ejhBprBrP8BYGxsBA3BrPNhDxJBrTXXvHi3-ZQ?e=jMZihi
       */
       /* body:after {
        content: url(img/ok/logo.png) ;
        position: fixed;
        bottom: 80px;
        left: -1080px;
        transform: scale(.06);
        height: 10px;
    } */

	</style>
</head>

<body style="background-color: whitesmoke;">

<div class="reveal">    
    <div class="slides">

<!-- 
https://odsc.com/speakers/autoencoders-a-magical-approach-to-unsupervised-machine-learning/

75 min workshop

Autoencoders – a Magical Approach to Unsupervised Machine Learning

Autoencoders are a special kind of neural network architecture. They are trained by reproducing an input as accurately
as possible in an unsupervised way. This is done by encoding the input into a latent representation that forces the
network to learn some kind of a abstraction and then reconstructing the original input from that representation.

The benefit of this is hard to see at first. But we can make use of this approach in at least two ways. First, we can
take the latent representation that should now contain the abstract pattern of the inputs. This can be used for
dimensionality reduction, clustering, or visualization. Second, we can use the reconstruction error as a measure of how
well something fits the learned concept. This is used to find outliers even for the most complex input types.

In this workshop we will illustrate both approaches using a consistent single example. We will use TensorFlow in a Colab
notebooks, so all you need is a recent version of Chrome and a Google login. You will not need prior knowledge with
TensorFlow, but need a good understanding of how training neural networks work as a prerequisite.
 -->

 <!-- <section data-markdown class="todo">
	<textarea data-template>
### Sources

* /home/olli/ml-workshop/2019-embeddings.html
* /home/olli/ml-workshop/2019-unsupervised.html
* /home/olli/ml-workshop/2020-ae-anomaly.html
* /home/olli/ml-workshop/2020-ml-essentials-embeddings.html
* /home/olli/ml-workshop/2021-m3-autoencoder.html
* Folien von ODSC West 2022: https://drive.google.com/file/d/1LMaU88hLOFKqs_ni-uMh4-VsD3j_j7j1/view
</textarea>
</section>
 -->

  <section data-markdown class="todo">
	<textarea data-template>
* Zusammenfassung
* Bei half-day
  1. Teil: MINIST reconstruction
  2. Teil nach Pause: Anomalies
  * Übungen für Anomalies einbauen
</textarea>
</section>

<section data-markdown class="preparation">
    <textarea data-template>

- Notebook auf Colab öffnen: https://bit.ly/odsc-europe-autoencoder-notebook
- Notebook lokal öffnen und schon einmal durchlaufen lassen (Training dauert lange): 

```bash
conda activate tf
cd ml-resources/notebooks/
jupyter notebook
```
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
# Autoencoders
### a Magical Approach to Unsupervised Machine Learning

ODSC Europe 2023, https://odsc.com/speakers/autoencoders-a-magical-approach-to-unsupervised-machine-learning/

Oliver Zeigermann

<img src="img/bit.ly_odsc-europe-autoencoder.png" style="height: 200px;">

Slides: https://bit.ly/odsc-europe-autoencoder
Notebook: https://bit.ly/odsc-europe-autoencoder-notebook

<!-- https://djcordhose.github.io/ml-resources/2023-autoencoder-odsc-europe.html -->
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
- Ausblick und Zusammanfassung (ich habe sowieso genug Material, kann zur Not entfallen)
    </textarea>
</section>


<section data-markdown class="fragments">
    <textarea data-template>
## TL'DR

* We train a NN to be able to reconstruct "correct" screenshots from a compressed state well.
* Then we compress "unknown" screenshots and reconstruct them with the trained NN.
* Then we compare them against their uncompressed state -> if there is little difference, the unknown screenshot was probably a correctly looking one, else, something might be broken
</textarea>
</section>


<section data-markdown>
	<textarea data-template>
## Agenda

1. What is an Autorencoder and why would you want one?
1. Our use case for today
1. Hands-On / Notebook
1. What else and Wrap Up
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Agenda

1. *What is an Autorencoder and why would you want one?*
1. Our use case for today
1. Hands-On / Notebook
1. What else and Wrap Up
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Autoencoder: strategy card

* Data
  * Input: <span class="fragment" style="font-weight: bold;">All kinds of data are possible</span> 
  * Output: <span class="fragment" style="font-weight: bold;">The same data</span>
* Learning strategy: <span class="fragment" style="font-weight: bold;">Unsupervised</span>  
* Model architecture: <span class="fragment" style="font-weight: bold;">Neural network, symmetric with bottleneck</span>
* Loss: <span class="fragment" style="font-weight: bold;">typically MSE, all NN losses possible</span>


<div>
<img src='img/autoencoder_schema.jpg' style="height: 200px">
<br>
<small>

https://blog.keras.io/building-autoencoders-in-keras.html

</small>
</div>
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Autoencoders for Abstraction
        
* assumption: there are underlying concepts that can be used for abstraction
* project instances to latent representation
* the less the capacity of the latent representation, the higher the abstraction
* means to restrict capacity:
  * _undercomplete_ (capacity of latent representation << dim of inputs)
    * L2 to further compress latent a bit
  * _overcomplete_ (capacity of latent representation >= dim of inputs)
    * use L1 to increase sparsity of embedding when having dim > 2, to have an additional restriction (often gives better results)


<small>

https://www.deeplearningbook.org/contents/autoencoders.html</small>

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Why Autoencoder?

* Compression
* Data denoising
* Dimensionality reduction
* Building an abstract representation for further use
* Clustering (also for data visualization)
* Outlier detection

</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Example: spotting anomalies in ECG signals

<a href='https://victordibia.github.io/anomagram/#/'>
<img src='img/anomagram-inference.gif' height="450">
</a>
<br>
<small>

https://github.com/victordibia/anomagram        
https://victordibia.github.io/anomagram/#/
    
</small>
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Agenda

1. What is an Autorencoder and why would you want one?
1. *Our use case for today*
1. Hands-On / Notebook
1. What else and Wrap Up
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Our sample application

<img src='img/autoencoder/ML_0801_app.png'>

Simple, but complex enough to show typical error cases

https://djcordhose.github.io/react-showcase/
</textarea>
</section>


<section data-markdown>
## What kind of errors can only be found on a visual level? 

</section>

<section data-markdown>
<textarea data-template>
### Typical problem case 1: i18n

Ideally, new texts should not cause failure, but this does

<img src='img/autoencoder/ML_0802_bug_i18n.png'>

Not nice, but does not necessarily jeopardize the usability of the application
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Typical problem case 2: Evil overflows

The button is still there, but invisible and therefore not clickable by humans

<img src='img/autoencoder/ML_0803_bug_overflow.png'>

Happens only on certain inputs, but makes the application unusable
</textarea>
</section>

<!-- <section data-markdown>
	<textarea data-template>
### Autoencoders 

* Smart way of dimensionality reduction to latent space 
* Can be combined with dimensionality reduction, clustering and outlier detection

<div class="container">
	<div class="col">
		<img src="img/autoencoder-latent-space.png">
	</div>
	<div class="col">
		<img src="img/autoencoder-clustering.png">
	</div>

</div>

</textarea>
</section>

 -->
<section data-markdown>
	<textarea data-template>
## Agenda

1. What is an Autorencoder and why would you want one?
1. Our use case for today
1. *Hands-On / Notebook*
1. What else and Wrap Up
</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### Our approach

* Autoencoder is trained with Gold Master (considered correct) (input and output)
* we assume that before the change the application looked mostly as expected
  * so Gold Master mainly has correct screen shots
* validation data set may be the new (minor) release 
  * probably contains regressions
* Autoencoder thus learns how the application should normally look like

<img src='img/autoencoder/training_en.png' style="height: 250px;">


</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Very small bottleneck forces extreme abstraction


<img src='img/autoencoder/ML_0811_h.png'>

<!-- Result of stacked convolutional layers directly before bottleneck   -->

</textarea>
</section>

<section data-markdown>
<textarea data-template>
## Notebook using Google Colab and TensorFlow

_Hands-On: Walk through_

https://bit.ly/odsc-europe-autoencoder-notebook

### 45 Minutes
</textarea>
</section>


<section data-markdown>
	<textarea data-template>
### Agenda

1. What is an Autorencoder and why would you want one?
1. Our use case for today
1. Hands-On / Notebook
1. *What else and Wrap Up*
</textarea>
</section>

<!-- <section data-markdown class="todo">
	<textarea data-template>
### Wie vergleicht man Embeddings? 
</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
- Autoencoders for Adversarial Attacks

- https://docs.seldon.io/projects/alibi-detect/en/stable/ad/methods/adversarialae.html
- https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html
- https://docs.seldon.io/projects/alibi-detect/en/stable/examples/alibi_detect_deploy.html#4.-Drift-detection-with-Kolmogorov-Smirnov
- https://arxiv.org/abs/2002.09364
</textarea>
</section>
 -->
<section data-markdown>
## This approch is taken in other domains as well
### First example: is the ISS working ok?

If the model is able to reconstruct observations of nominal states with a high accuracy, it will have difficulties reconstructing observations of states which deviate from the nominal state. Thus, the reconstruction error of the model is used as an indicator for anomalies during inference, as well as part of the cost function in training.

https://blog.tensorflow.org/2020/04/how-airbus-detects-anomalies-iss-telemetry-data-tfx.html
</section>


<section data-markdown>
	<textarea data-template>
### Fitbit for cows as anomaly detection

_are they beginning to become lame?_

https://youtu.be/MtJ5HAEAGFU

</textarea>
</section>


<section data-markdown class="todo">
	<textarea data-template>
### Elderly Care

* are people moving around as expected?
* are they falling?
* are they lying on the floor?
* are they fully dressed?

</textarea>
</section>

<!-- <section data-markdown class="todo">
    <textarea data-template>
### Mehr Links

* Mehr Beispiele für Autoencoder: https://colab.research.google.com/github/DJCordhose/ml-workshop/blob/master/notebooks/tf-intro/2020-01-autoencoder.ipynb
* Breite Auswahl an Beispielen aus dem Bereich Autoencoder, unsere Architektur ist davon abgeleitet: https://colab.research.google.com/github/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb 

* Academische Betrachtungen
  * https://fleuret.org/dlc/#lecture-7
    * https://twitter.com/francoisfleuret/status/1382708204468060171
  * https://www.deeplearningbook.org/contents/autoencoders.html
  * Deconvolution erklärt: https://arxiv.org/pdf/1603.07285v1.pdf, S. 18ff
</textarea>
</section>
 -->

 <section data-markdown>
	<textarea data-template>
### Application: reconstructing images

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/autoencoder_mnist_reconstruction_odsc.ipynb?hl=en
</textarea>
</section>


<section data-markdown class="todo">
	<textarea data-template>
### Wrap Up 
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
# Thanks a lots

## Autoencoders – a Magical Approach to Unsupervised Machine Learning

ODSC Europe 2023

Slides: https://bit.ly/odsc-europe-autoencoder

Stay in touch if you like

<a href='https://twitter.com/DJCordhose'>@DJCordhose</a>

<a href='https://www.linkedin.com/in/oliver-zeigermann-34989773/'>https://www.linkedin.com/in/oliver-zeigermann-34989773/</a>

    </textarea>
</section>

</div>
</div>


<script src="reveal.js/dist/reveal.js"></script>
<script src="lib/jquery.js"></script>
<script>
    const printMode = window.location.search.match(/print-pdf/gi);
    const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
        window.location.hostname.indexOf('127.0.0.1') !== -1;
    const isPresentation = isLocal && !printMode;
    const isPublic = !isPresentation;

    $('.hide').remove();

    if (isPresentation) {
    } else {
        // only applies to public version
        $('.todo').remove();
        $('.preparation').remove();
        $('.local').remove();
    }

    Reveal.addEventListener('ready', function (event) {
        // applies to all versions
        $('code').addClass('line-numbers');

        $('.fragments li').addClass('fragment')

        // make all links open in new tab
        $('a').attr('target', '_blank')

        if (isPresentation) {
            // only applies to presentation version
            Reveal.configure({ controls: false });
        } else {
            // only applies to public version
            $('.fragment').removeClass('fragment');
        }

        // we do not like fragments
        // $('.fragment').removeClass('fragment');

    });

</script>

<script src="reveal.js/plugin/notes/notes.js"></script>
<script src="reveal.js/plugin/markdown/markdown.js"></script>
<script src="reveal.js/plugin/highlight/highlight.js"></script>
<script>
    // More info about initialization & config:
    // - https://revealjs.com/initialization/
    // - https://revealjs.com/config/
    Reveal.initialize({
        hash: true,
        controls: true,
        progress: true,
        history: true,
        center: true,
        width: 1100,
        slideNumber: true,
        hideInactiveCursor: false,
        transition: 'none', // none/fade/slide/convex/concave/zoom


        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
    });
</script>


</body>

</html>
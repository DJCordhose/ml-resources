<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

	<title>Bilderkennung</title>

	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
	<link rel="stylesheet" href="reveal.js/dist/theme/white.css">

	<!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
	<style>
		.right-img {
			margin-left: 10px !important;
			float: right;
			height: 500px;
		}

		.todo:before {
			content: 'TODO: ';
		}

		.todo {
			color: red !important;
		}

		code span.line-number {
			color: lightcoral;
		}

		.reveal pre code {
			max-height: 1000px !important;
		}

		img {
			border: 0 !important;
			box-shadow: 0 0 0 0 !important;
			height: 450px;
		}

		.reveal {
			-ms-touch-action: auto !important;
			touch-action: auto !important;
		}

		.reveal h1,
		.reveal h2,
		.reveal h3,
		.reveal h4 {
			/* letter-spacing: 2px; */
			font-family: 'Calibri', sans-serif;
			/* font-family: 'Times New Roman', Times, serif; */
			/* font-weight: bold; */
			color: black;
			/* font-style: italic; */
			/* letter-spacing: -2px; */
			text-transform: none !important;
		}

		.reveal em {
			font-weight: bold;
		}

		.reveal section img {
			background: none;
		}

		.reveal img.with-border {
			border: 1px solid #586e75 !important;
			box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
		}

		.reveal li {
			margin-bottom: 8px;
		}

		/* For li's that use FontAwesome icons as bullet-point */
		.reveal ul.fa-ul li {
			list-style-type: none;
		}

		.reveal {
			/* font-family: 'Work Sans', 'Calibri'; */
			font-family: 'Calibri';
			color: black !important;
			font-size: xx-large;
		}

		.container {
			display: flex;
		}

		.col img {
			height: auto;
		}

		.col,
		col-1 {
			flex: 1;
		}

		.col-2 {
			flex: 2;
		}

	/* https://intranet.openknowledge.de/plugins/servlet/mobile?contentId=18612939#content/view/18612939
      https://intranet.openknowledge.de/pages/viewpage.action?pageId=16157867
      https://openknowledgede.sharepoint.com/:p:/s/slides/EYWbMPz2ejhBprBrP8BYGxsBA3BrPNhDxJBrTXXvHi3-ZQ?e=jMZihi
       */
       body:after {
        content: url(img/ok/logo.png) ;
        position: fixed;
        bottom: 80px;
        left: -1080px;
        transform: scale(.06);
        height: 10px;
    }

	</style>

</head>

<body style="background-color: whitesmoke;">
	<div class="reveal">
		<div class="slides">
<!-- 
Stand der Kunst in der Bilderkennung

Bilderkennung ist die Paradedisziplin des Maschinellen Lernens. Gerade in diesem Bereich sind mit künstlichen Neuralen
Netzwerken Erkennungsraten und eine Robustheit möglich, an die mit klassischen Verfahren nicht zu denken war. Allerdings
sind traditionelle Ansätze in manchen Bereichen als Alternative oder in Kombination mit Neuronalen Netzen immer noch
sinnvoll.

In diesem Vortrag führe ich daher durch die folgenden Themen:

1. Traditionelle Ansätze

Was sind diese Ansätze? Wo liegt deren Stärke und wo sind die Grenzen?

2. Neuronale Netzwerke

Wann sind diese sinnvoll und in welcher Architektur? Was braucht man, um sie zu trainieren?

3. Was kommt als nächstes?

Es gibt neuere Ansätze, die in der praktischen Anwendung bisher nicht erprobt sind, aber Potential haben, in der Zukunft
eine größere Rolle zu spielen. Dazu gehören Ansätze auf Basis von Transformern und Systeme, die realitätsnahe Bilder
erzeugen können wie GANs und DALLE-2.
			 -->

<section data-markdown class="todo">
	<textarea data-template>
* Fotos der Ringe machen mit Teachable Machine
  * Auch Hintergrund
  * Auch Hand ohne Ring ()

	</textarea>
</section>
			

			<section data-markdown>
				<textarea data-template>
# Stand der Kunst in der Bilderkennung

Oliver Zeigermann
    </textarea>
			</section>

<section data-markdown>
	<textarea data-template>
### Agenda

1. Vergangenheit: Klassische Bilderkennung
1. Gegenwart: Deep Learning
1. Zukunft: Transformers und Co
	</textarea>
</section>
			
<section data-markdown>
	<textarea data-template>
### Agenda

1. _Vergangenheit: Klassische Bilderkennung_
1. Gegenwart: Deep Learning
1. Zukunft: Transformers und Co
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Beispiel: Wie kann man diese beiden Arten automatisch unterscheiden?

<img src="img/rings.jpg">

Gleiche Form, gleiches Material
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Unterschiedliche Größe

* es gibt Verfahren, die Kreise zuverlässig erkennen können
* das bekannteste Verfahren ist die Hough-Transformation
* anhand der Größe der Kreise könnten wir den Unterschied ablesen
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Die Parameter sind Gefummel, aber mit ein bisschen Erfahrung bekommt man das hin 

```
aperture = 21
img_gray_blur = cv.medianBlur(img_gray, ksize=aperture)

threshold_canny_edge_detector = 100
threshold_circle_centers = 30

circles = cv.HoughCircles(
    image=img_gray_blur,
    method=cv.HOUGH_GRADIENT,
    dp=1,
    minDist=rows/8,
    param1=threshold_canny_edge_detector, 
    param2=threshold_circle_centers,
    minRadius=0, 
    maxRadius=0)
```

https://github.com/DJCordhose/ml-resources/blob/main/notebooks/image/classic.ipynb

https://docs.opencv.org/4.x/d4/d70/tutorial_hough_circle.html

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Hough-Transformation

<img src="data/ring/stone-top-detection.jpg">

133 vs 150

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Aber nun...

<img src="data/ring/stone-tilt-detection.jpg">

114 vs 116

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Andere Umgebung und Schatten

<img src="data/ring/wama-tilt-detection.jpg">

145 vs 151

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Ohje

<img src="data/ring/table-top-flash-detection.jpg">

</textarea>
</section>


<section data-markdown>
	<textarea data-template>
### Unter Laborbedingungen ist das sehr brauchbar

* Objekte mit klaren, am besten geometrische Formen (z.B. Kreise) oder aus diesen zusammengesetzt
* Konstanter Hintergrund, der sich klar vom zu erkennenden Objekt abhebt
* Konstante Lichtquelle
* Konstante Kamera mit
* Konstanter Entfernung, Winkel und Brennweite
* Generell möglichst konstante Umgebung beim erstellen der Fotos (kein Staub, Sonnenlicht, etc.)

_Aber für die freie Wildbahn eine große Herausforderung_
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Python-Werkzeuge für klassischen Bilderkennung

* OpenCV
  * https://docs.opencv.org/4.x/
  * https://pypi.org/project/opencv-python/ 
* scikit-image
  * https://scikit-image.org/
</textarea>
</section>


<section data-markdown>
	<textarea data-template>
### Wichtigste Techniken der klassischen Bilderkennung

* Faltungen (Blur/Sobel/Sharpen): https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html
* Edge-Detection: https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html
* Konturen und Bounding Boxes: https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html
* Morphologische Operationen (Opening/Closing): https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
* Segmentierung: https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html

https://docs.opencv.org/4.x/d2/d96/tutorial_py_table_of_contents_imgproc.html
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Und nun?

<img src="data/ring/hand.jpg">

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Agenda

1. Vergangenheit: Klassische Bilderkennung
1. _Gegenwart: Deep Learning_
1. Zukunft: Transformers und Co
	</textarea>
</section>
			

<section data-markdown>
	<textarea data-template>
### Im Mittelalter wussten Künstler zwar von der Existenz von Elefanten, aber sie konnten sich nur auf die Beschreibungen von Reisenden stützen
<img src='img/elephants/RUwdSMK.jpeg'>

<small>

https://imgur.com/gallery/MpRBy
</small>
	
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
## Manche Sachen kann man nicht erklären, sondern nur zeigen

### The way that can be spoken is not the eternal way
### The name that can be named is not the eternal name
		
Tao Te Ching		
</textarea>
</section>


<section data-markdown>
	<textarea data-template>
## Machine Learning

_Ein Ansatz zur Entwicklung von Software, bei dem die Software nicht von Hand geschrieben wird, 
sondern die Maschine auf der Grundlage gegebener Beispiele und Rahmenbedingungen herausfindet, 
was zu tun ist_

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Lösung mit Machine Learning
### Beibringen, nicht programmieren!

<a href='https://teachablemachine.withgoogle.com/'>
    <img src='img/teachable-machine.png' style="height: 300px;">
</a>

_Live Demo_

https://teachablemachine.withgoogle.com/

</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Wann macht ML Sinn?

_Die Lösung des vorliegenden Problems ist unbekannt oder schwer zu spezifizieren_

_Und_

* Es liegen Daten mit einer klaren, einfache Eingabe und bestenfalls auch passender Ausgabe vor 
* Es gibt Muster in der Eingabe, die zur Vorhersage verwendet werden können
* Die Lösung des Problems kann Fehler oder Unsicherheiten tolerieren
* Wir sind bereit und in der Lage, in einer initialen Phase Experimente mit offenem Ausgang durchzuführen
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Machine Learning Projekte laufen anders ab als klassische Projekte

<img src="img/sketch/phases-ml.png">

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Künstliche Intelligenz (KI) vs Machine Learning (ML)

<img src='img/se_ai_and_architecure.pptx.png'>

Wir lösen nur einzelne, gut abgehangene Teile, wollen keine generelle KI bauen
</textarea>
</section>

<section data-markdown>
	<textarea data-template>
### Agenda

1. Vergangenheit: Klassische Bilderkennung
1. Gegenwart: Deep Learning
1. _Zukunft: Transformers und Co_
	</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
* https://www.kaggle.com/code/odins0n/jax-flax-tf-data-vision-transformers-tutorial
	</textarea>
</section>

<section data-markdown class="todo">
	<textarea data-template>
### Den Fortgeschrittenen Kram aus 2022-image-recognition.html
* Transformers
* GANs
* DALLE-2 		
	</textarea>
</section>


<section data-markdown class="todo">
	<textarea data-template>
### Tiefenbilder		
	</textarea>
</section>


<section data-markdown class="todo">
	<textarea data-template>
### Zusammenfassung

	</textarea>
</section>


<section data-markdown>
	<textarea data-template>
# Vielen Dank
## Stand der Kunst in der Bilderkennung

Bleibt gern im Kontakt

https://www.linkedin.com/in/oliver-zeigermann-34989773/

oliver.zeigermann@openknowledge.de

Twitter: @DJCordhose

Diese Folien: https://djcordhose.github.io/ml-resources/2022-ods.html
</textarea>
</section>
		</div>
	</div>

	<script src="reveal.js/dist/reveal.js"></script>
	<script src="lib/jquery.js"></script>
	<script>
		const printMode = window.location.search.match(/print-pdf/gi);
		const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
			window.location.hostname.indexOf('127.0.0.1') !== -1;
		const isPresentation = isLocal && !printMode;
		const isPublic = !isPresentation;

		$('.hide').remove();

		if (isPresentation) {
		} else {
			// only applies to public version
			$('.todo').remove();
			$('.preparation').remove();
			$('.local').remove();
		}

		Reveal.addEventListener('ready', function (event) {
			// applies to all versions
			$('code').addClass('line-numbers');

			$('.fragments li').addClass('fragment')

			// make all links open in new tab
			$('a').attr('target', '_blank')

			if (isPresentation) {
				// only applies to presentation version
				Reveal.configure({ controls: false });
			} else {
				// only applies to public version
				$('.fragment').removeClass('fragment');
			}

			// we do not like fragments
			// $('.fragment').removeClass('fragment');

		});

	</script>

	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			controls: true,
			progress: true,
			history: true,
			center: true,
			width: 1100,
			slideNumber: true,
			hideInactiveCursor: false,


			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
		});
	</script>


</body>

</html>
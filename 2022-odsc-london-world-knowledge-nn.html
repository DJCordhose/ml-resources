<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>World Knowledge Priors</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }
        .reveal section.left ul {
            width: 100%;
          }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <!-- 
Welt- und Domänenwissen für neuronalen Netze
 
Neuronale Netze können jede Funktion approximieren, sie haben jedoch nicht die geringste Ahnung von allgemeinem Wissen über die Welt. 
Dieser Mangel lässt sie oft kläglich scheitern, insbesondere bei der Extrapolation in Bereiche, die nicht durch Trainingsdaten abgedeckt sind.
 
Wir Menschen verfügen über dieses Welt- und Domänenwissen, das Deep-Learning-Modelle viel robuster werden lassen und sogar
Extrapolation erlauben könnte. Zum Beispiel lösen sich Objekte bei der Bilderkennung meistens nicht einfach in Luft auf und es gibt die Tendenz, dass Menschen mit zunehmendem Alter erst schneller, aber dann langsamer werden und irgendwann auch sterben. Nur, wie kodieren wir dieses Wissen?
 
Dieser Vortrag ist ein Überblick über bekannte Methoden, einschließlich der Wahl des richtigen Losses, der Erzwingung von Sparsity,
der Wahl guter Dimensionen, Lattices, Arten von Netzwerkschichten und - nicht zuletzt - augmentierte Trainingsdaten.
 
M3 700 Zeichen kurzverversion:

Neuronale Netze können jede Funktion approximieren, sie haben jedoch nicht die geringste Ahnung von allgemeinem Wissen über die Welt. 

 
Dieser Vortrag ist ein Überblick über bekannte Methoden, einschließlich der Wahl des richtigen Losses, der Erzwingung von Sparsity,
der Wahl guter Dimensionen, Lattices, Arten von Netzwerkschichten und - nicht zuletzt - augmentierte Trainingsdaten.

Vorkenntnisse:

Ein grundsätzliches Verständnis wie neuronale Netze trainiert werden und Vorhersagen machen.

Lernziele:

Teilnehmer bekommen eine Idee von der Herausforderung Weltwissen in einen Trainingsprozess einfließen zu lassen und einen Überblick über die existierenden Möglichkeiten.
 
Neuer Abstract M3

Wie kann man Weltwissen ins Machine Learning einbringen?

Machine Learning Modelle verfügen a priori nicht über allgemeines Weltwissen. 
Dieser Mangel lässt sie oft kläglich scheitern, vor allem, wenn sie auf Bereiche extrapolieren, die nicht durch Trainingsdaten abgedeckt sind. 

Wir Menschen verfügen über dieses Welt- und Domänenwissen, das Machine Learning Modelle viel robuster werden lassen und sogar
Extrapolation erlauben könnte. So sind z.B. Objekte in der Bilderkennung häufig invariant zu einer bestimmten Reihe von Parametern, 
wie zum Beispiel der Position im Raum, oder man weiß, dass niemand über 150 Jahre alt ist oder Autos typischerweise nicht die Schallgeschwindigkeit erreichen.

Dieser Vortrag ist ein Überblick über bekannte Methoden, dieses wissen in einen Machine Learning Prozess einzubringen. 



-->
<!-- 

Pydata London:

Teaching world knowledge to a machine learning model

Abstract

Machine learning models do not have a priori general knowledge of the world. 
This lack often causes them to fail miserably, especially when they extrapolate to domains not covered by training data. 

We humans have this world and domain knowledge that could make machine learning models much more robust and even allow for extrapolation. 

Give give some examples: Objects in image recognition are often invariant to their relative position. 
It is known that human is over 150 years old. Cars typically do not reach the speed of sound. 

This talk is an overview of known methods to incorporate this knowledge into a machine learning process. 

Description

We will have general overview and focus a bit more on neural networks.
Topics will include: data augmentation, Bayesian priors, parametric vs non-parametric models, regularization, Markov chains, and more.

You will need a basic understanding of how machine learning works, but no knowledge about libraries, as this talk will be more conceptual than code driven. 
 -->

            <!-- Title: How to teach our world knowledge to a neural network?

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to become much more robust and even to extrapolate. But how do we encode this?

This talk is a survey on known methods including choosing the right loss, forcing sparsity, choose good dimensions, lattices, types of network layers, and - last but not least - augmented training data. 

There will also be a critique of too much trust in auto tuning libraries. They might win you a Kaggle competition, but might spoil your real-world applicability.

I will show actual code on different examples and share the code for you to take home as a starting point.

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though), but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the world knowledge you have.

Pitch: Deep Learning models are notorious for not being able to extrapolate from their area of training data. However, by encoding your world knowledge as priors you can at least push it in the right direction. It might even be the most important skill of a deep learning engineer to know how to do that.

Workshop:

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common
knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by
training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to
become much more robust and even to extrapolate. But how do we encode this?

Based on code examples we will go through the known methods including choosing the right loss, forcing sparsity, choose
good dimensions, lattices, types of network layers, and - last but not least - augmented training data.

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though),
but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the
world knowledge you have.


Format: Workshop oder Talk

Level: Intermediate

Konferenzen:
-  ODSC Europe / West: https://odsc.com/europe/call-for-speakers-europe/
- M3
- Scipy

Inhalte:
- GenerelL: Pre oder Post Processing kodiert oder dekodiert Weltwissen
- Data Augmentation using world knowledge
  - might explode with dimensions
  - augmented data might outweight "real" data 
- Sparsity
- CNN
- RNN
- Lattice
- Losses (xent vs mse)
- Why auto tuning might not be such a good idea (overfits on val data), but real priors might not even be obeyed
- Beispiel mit Lattice, Extrapolation und Tweet von Fchollet
- Daten-Beispiele selbst gemalte Bilder oder Sinus
- Hidden Markov Models
  * https://en.wikipedia.org/wiki/Markov_chain
- Kalman Filter
  * https://en.wikipedia.org/wiki/Kalman_filter

Weltwissen hauptsächlich Frage der Architektur
- Traditionelle Systeme instrumentieren viele kleine Modelle als Pattern matcher viel besser als
- Großes System als Blackbox

Großes System als Blackbox
Eigener Talk
- die wichtigste Architektur Frage im Machine Learning
- Ein großes Modell oder viele kleine traditionell instrumentiert

---

Talk: ODSC Europe

Why you should prefer many small models over a single large one

When designing a solution using machine learning one of the central architectural questions is whether you
should use a set of small models orchestrated by traditional code or a single big one that just figures out
things from beginning to end.

In this talk I take the standpoint that a single large one should be avoided for many reasons. The main
reason for choosing small ones is to keep being in control as the human domain expert. This applies to
training as well as putting in domain knowledge your models can not possibly have.

While this might also be of interest in the academic world in context of whether deep learning is the
solution to all in this talk we will look at it from a practical perspective.

Of course this is an over-generalization, but I found this to be true in all the projects I have
participated in and in many other common ones.


---

Talk: QCon

Title: The most important architectural decision in machine learning: many small models over a single large one?

actionable takeaways

What are the most important architectural questions in machine learning? 
Why architecture for machine learning has a special place in the world of software engineering. 
Among the important decisions you need to make early which are the ones that are especially hard to change. 
Why such a seemingly harmless question has so much emotional potential.

While sounding harmless at first sight, there is also a lot of emotional potential in this question.




what is by far the most important and hardly correctable architectural decision in retrospect

As another teaser: doesn't look important at first, and requires much explanation why it is so

---

Scipy Updated und genereller

How to bring world knowledge into a machine learning model?

Machine learning models in general and neural networks in particular do not have common knowledge of the world a priori.
This lack often makes them fail miserably, especially when extrapolating to areas not covered by training data.

We, as human beings have knowledge about the world and our domains of expertise, that would allow machine learning
models to become much more robust and even to extrapolate. But how do we encode this?

This talk is a survey of known methods that tackle the issue from different angles. We will look at baking knowledge
into deep neural networks as well as combining machine learning models with well known classic AI techniques. Techniques
include Markov chains, rule systems, and augmented training data for approaches from the outside and choosing the right
loss, forcing sparsity, good dimensions, lattices, and types of network layers for bringing a prior into neural
networks.
-->


<!-- ODSC London:
https://odsc.com/europe/
90 min

Neural networks are powerful approximators for any function. However they do not have the slightest idea of common
knowledge of the world which often makes them fail miserably, especially when extrapolating to areas not covered by
training data.

We, as human beings have that knowledge about the world and our domains of expertise, allowing deep learning models to
become much more robust and even to extrapolate. But how do we encode this?

Based on code examples we will go through the known methods including choosing the right loss, forcing sparsity, choose
good dimensions, lattices, types of network layers, and - last but not least - augmented training data.

None of the techniques shown are new and you might already know a good chunk of them (probably not all of them, though),
but maybe you have not looked at them from the perspective of setting priors for your deep learning by encoding the
world knowledge you have. -->


        <!-- <section data-markdown>
            <textarea data-template>
### Links

* Why Do Better Loss Functions Lead to Less Transferable Features?" https://twitter.com/skornblith/status/1469132061579620355
* Implicit inference of 3D vision: This short paper in the journal i-Perception presents a disconcerting visual illusion spotted “in the wild”: how stackable chairs, viewed from a certain angle, mess with your head [read more, paper: https://t.co/ppu9j0pyIs] https://t.co/r2Sdie3UdF
(https://twitter.com/Rainmaker1973/status/1489209455489212416?t=gxzQxv4J1yKQWVNnVkQ6bA&s=03)
* What I’ve learned about making synthetic data work for training ML models: (https://twitter.com/russelljkaplan/status/1490303023267999744?t=QHQ_IkP8zs8LEzzr6bWmQQ&s=03)  
</textarea>
        </section> -->
    

  <section data-markdown class="local hide preparation">
    <textarea data-template>
### Vorbereitung

* Nice to have: Lattice Beispiel basteln
* https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/priors/extrapolate_lattice.ipynb?hl=en

    </textarea>
  </section>


  <section data-markdown class="todo">
    <textarea data-template>
### Idee für Sparsity Plot klauen        
* https://towardsdatascience.com/sparse-autoencoder-neural-networks-how-to-utilise-sparsity-for-robust-information-encoding-6aa9ff542bc9
* Warum Robust? Warum Sparsity? Nochmal nachlesen in ursprünglicher Quelle, dem akademischen
</textarea>
</section>

        
<section data-markdown>
    <textarea data-template>
# How to teach our world knowledge to a neural network?

Workshop at ODSC Europe, London 2022, https://odsc.com/europe/
Oliver Zeigermann

Slides: https://bit.ly/2022-odsc-priors

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Who is Olli

<div style="display: flex;">
<div style="flex: 50%;">
<a href='https://oreilly.de/produkt/machine-learning-kurz-gut-2/'>
<img src='img/ml-buch-v2.jpg' height="400">
</a>
</div>
<div style="flex: 50%; font-size: x-large;">
<img src='img/olli-opa.jpeg'>
</div>
</div>
<p>
<a target="_blank" href="mailto:oliver.zeigermann@openknowledge.de">Oliver Zeigermann</a>:
Head of AI@OpenKnowledge
</p>    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Where did the Smurf go?

<video src="img/smurf/smurf-short.mp4" controls>

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
## This isn't so much about whether this is a great trick, but rather...

* **object permanence** https://en.wikipedia.org/wiki/Object_permanence
* is a knowledge about the world we are so certain of
* we get stressed when it is challenged
* and immediately start thinking: where did it go?
* basis for a large number of magical tricks

</textarea>
</section>

<section data-markdown class="fragments">
    <textarea data-template>
### World knowledge 

* humans have a basic understanding of the world
* be it about the physics of normal objects or about the properties of people 
* we also expect this from an intelligent automatic system
* if a system does not fulfill this we are disappointed and our trust in the system decreases 
        
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Isn't Encoding World Knowledge just applied statistics and mathematics?
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### In a nutshell: Encoding World Knowledge

What objective do you phrase in your learning experiment?

- type of learning
  - supervised learning, unsupervised learning, reinforcement learning
- Input and output
  - feature extraction / preprocessing: what is really relevant?
- general architecture
  - type of model, network capacity , parametric
- reward and observation for RL
  - shape learning objective
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Modeling choices encode strong assumptions about the data

<img src="img/world-knowledge/fchollet-model-priors.png">

https://twitter.com/fchollet/status/1439799099176357894
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
## Priors

<div class="container">
<div class="col">
<img src="img/world-knowledge/weak-prior.jpeg">
</div>
<div class="col">
    <img src="img/world-knowledge/strong-prior.jpeg">
    </div>
    </div>

https://twitter.com/fchollet/status/1450871559803916290
</textarea>
</section>

<!-- <section data-markdown>
    <textarea data-template>
### Did it go here?

<img src="img/smurf/smurf-fallen.jpg">

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### No, it is really gone

<video src="img/smurf/smurf-full.mp4" controls>

</textarea>
</section> -->

<!-- <section data-markdown class="todo">

- Wie Zaubertricks funktionieren: https://twitter.com/TheFigen/status/1511035101878042629?s=20&t=CXyCqvLcGi3WQECLmzw_Fg
</section> -->

<section data-markdown>
    <textarea data-template>
## Mode
### We go through notebooks on Colab, you will get some time for experimentation        
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Example 1: Basic Model Architecture

<div class="container">
    <div class="col">
        <img src="img/world-knowledge/regression-linear.png">
    </div>
    <div class="col">
        <img src="img/world-knowledge/regression-non-linear.png">
    </div>
</div>

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/priors/regression.ipynb?hl=en

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## Example 2: Advanced Model Architecture

<img src="img/world-knowledge/denoising.png">

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/priors/autoencoder-denoising.ipynb?hl=en

</textarea>
</section>

<section data-markdown>
### Regularization as a way to add world knowledge

Basics

* L1 as Sparsity enforcing prior
    * Use L1 if you know your images only contain few pixels
* L2 enforcing small values as prior
  * keep a certain parameter close a specific value
  * great visual example: https://twitter.com/matthen2/status/1520427990420791298     
    </section>
    
<section data-markdown>
    <textarea data-template>
## Example 3: Smart regularization

<div class="container">
    <div class="col">
        <img src="img/world-knowledge/extrapolation.png">
    </div>
    <div class="col">
        <img src="img/world-knowledge/adversarial_extrapolation.png">
    </div>
</div>
<small>

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/priors/interpolation.ipynb?hl=en
<br>
https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/priors/extrapolate_nsl?hl=en
<!-- <br>
https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/priors/extrapolate_lattice.ipynb?hl=en -->

</small>

</textarea>
</section>

<section data-markdown class="fragments">
### Most important - data

* real world projects typically don't operate on pre-collected data sets
* so you have to collect the data, but you can also choose what to collect
* make sure the data you collect covers the real world or at least the domain you are interested in
</section>

<section data-markdown class="fragments">
### Be aware of the natural bias of the data

* e.g. concerning people
  * height
  * age
  * gender
  * skin tone
  * hair styles
  * body ratio
  * disabilities
    * wheel chair
    * Crutch
* take care of negative classes
  * background
  * noise    

</section>

<section data-markdown class="fragments">
### General preprocessing

encode your assumptions, e.g.
* only general form and structure seen in an image are important
  * reduce resolution, apply closing
  * leads to faster training and better generalization
* a certain feature is highly correlated with the target value
  * but you know this is a bias in your data set
  * remove that feature from the input
  * live with the *worse* classifier

</section>

<section data-markdown class="fragments">
### Augmentation

* idea: generate more data from existing
* using invariants of the real world
  * e.g. a person is still a person no matter how far away
* concerns
  - might explode with dimensions
  - augmented data might outweigh "real" data
  - don't fool yourself: are you just using standard augmentation or real domain knowledge? 
* alternative: generate purely synthetic data
  * like GANs 
  * reality gap — the small differences between real and synthetic data that models may fixate on incorrectly, harming generalization (https://twitter.com/russelljkaplan/status/1490303023267999744)

</section>

<section data-markdown class="fragments">
### Foundation Models

_foundational models: trained on broad data at scale and are adaptable to a wide range of downstream tasks_

* promise to store the knowledge about the world in text form
* have a high capacity for learning
* can be trained on all data available in text form
* one day a general abstraction for everything?

https://arxiv.org/abs/2108.07258
</section>

<section data-markdown class="fragments">
### What else can you do?

* Markov-Chains
* Pre- and Post-Processing
* Parametric Models
  * We assume certain properties of the model, like being normally distributed, and just learn the parameters of such properties, like mean and std.
* Causality Models
  * often work by generating a set of models and seeing which performs best
</section>

<section data-markdown class="todo">
### Summray

</section>


<section data-markdown>
    <textarea data-template>
## Thanks for attending        
# How to teach our world knowledge to a neural network

Slides: https://bit.ly/2022-odsc-priors

Blog-Post: https://opendatascience.com/how-to-bring-our-world-knowledge-to-machine-learning/

### Stay in Contact if you like

Oliver Zeigermann, <a href='https://twitter.com/DJCordhose'>@DJCordhose</a>

https://www.linkedin.com/in/oliver-zeigermann-34989773/




</textarea>
</section>




        </div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>
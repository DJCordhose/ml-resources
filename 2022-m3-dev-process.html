<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=10.0, user-scalable=yes">

	<title>M3: ML Entwicklungsprozess</title>

	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
	<link rel="stylesheet" href="reveal.js/dist/theme/white.css">

	<!-- Theme used for syntax highlighted code -->
	<!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
	<style>
		.right-img {
			margin-left: 10px !important;
			float: right;
			height: 500px;
		}

		.todo:before {
			content: 'TODO: ';
		}

		.todo {
			color: red !important;
		}

		code span.line-number {
			color: lightcoral;
		}

		.reveal pre code {
			max-height: 1000px !important;
		}

		img {
			border: 0 !important;
			box-shadow: 0 0 0 0 !important;
			height: 450px;
		}

		.reveal {
			-ms-touch-action: auto !important;
			touch-action: auto !important;
		}

		.reveal h1,
		.reveal h2,
		.reveal h3,
		.reveal h4 {
			/* letter-spacing: 2px; */
			font-family: 'Calibri', sans-serif;
			/* font-family: 'Times New Roman', Times, serif; */
			/* font-weight: bold; */
			color: black;
			/* font-style: italic; */
			/* letter-spacing: -2px; */
			text-transform: none !important;
		}

		.reveal em {
			font-weight: bold;
		}

		.reveal section img {
			background: none;
		}

		.reveal img.with-border {
			border: 1px solid #586e75 !important;
			box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
		}

		.reveal li {
			margin-bottom: 8px;
		}

		/* For li's that use FontAwesome icons as bullet-point */
		.reveal ul.fa-ul li {
			list-style-type: none;
		}

		.reveal {
			/* font-family: 'Work Sans', 'Calibri'; */
			font-family: 'Calibri';
			color: black !important;
			font-size: xx-large;
		}

		.container {
			display: flex;
		}

		.col,
		col-1 {
			flex: 1;
		}

		.col-2 {
			flex: 2;
		}
	</style>

</head>

<body style="background-color: whitesmoke;">
	<div class="reveal">
		<div class="slides">

<section data-markdown class="local preparation hide">
- Jupyter Notebook in richtigem Environment
- Jupyter lab als Alternative zeigen	
</section>
<!-- 
https://www.m3-konferenz.de/veranstaltung-14114-0-der-entwicklungsprozess-eines-machine-learning-projekts.html
2.6.2022: 10:30 - 11:15
45 Minuten

Der Entwicklungsprozess eines Machine-Learning-Projekts

Ein Tutorial aus dem Internet zu programmieren oder an einem Kaggle-Wettbewerb teilzunehmen, das ist etwas ganz anderes
als die Entwicklung eines Machine-Learning-Modells, das als Teil eines Software-Stacks in Produktion gehen kann. Eine
der wesentlichen Herausforderungen ist, dass man einerseits interaktiv und explorativ vorgehen möchte, aber gleichzeitig
robuste und wartbare Software schreiben muss.

In diesem Talk beschreiben wir ein Modell für die unterschiedlichen Phasen eines Machine-Learning-Projekts und zeigen im
technischen Detail, welche Artefakte in welcher Phase entstehen und wie diese in andere Phasen übergehen. 
-->

<section data-markdown>
	<textarea data-template>
## Der Entwicklungsprozess eines Machine-Learning-Projekts                

M3 2022, https://www.m3-konferenz.de/veranstaltung-14114-0-der-entwicklungsprozess-eines-machine-learning-projekts.html

Oliver Zeigermann / oliver.zeigermann@openknowledge.de

Mikio Braun / mikiobraun@gmail.com

### Folien: https://bit.ly/m3-2022-ml-dev

	</textarea>
</section>


<!-- <section data-markdown>
	<textarea data-template>
<img src='img/model-eval.png'>

<small>

https://twitter.com/marktenenholtz/status/1528021809697792003</small>
		</textarea>
</section> -->

<section data-markdown>
	<textarea data-template>
		### ML in Produktion bringen
		1. Model trainieren & deployen
		2. ???
		3. Profit?
	</textarea>
</section>


			<!-- <section data-markdown class="todo">
### High Level Strategy ist wie ML Prozess

John Cutler (@johncutlefish) twitterte um 5:12 PM on Sa., Feb. 19, 2022:
Most teams jump from high level strategy/goals straight to feature ideas (w/ "success metrics")

The most successful teams
1. Have a strategy
2. Translate that into models
3. Add minimally viable measurement
4. Identify leverage points
5. Explore options
6. Run experiments https://t.co/EW8flIoA2M
(https://twitter.com/johncutlefish/status/1495068676508176385?t=U5bOFyDJOwl4eZdRhfmuLQ&s=03) 
</section> -->


<!-- <section data-markdown class="todo">
	<textarea data-template>

### Small Modules or one large monolith

<img src="img/sketch/small-model.jpg">

* Habe ich ein gutes Beispiel für Micro ML, dessen Eigenschaften öffentlich sind?

</textarea>	
	</section>


<section data-markdown class="todo">

Vorteil dickes NN: Konstantes Bedürfnis an Ressourcen
</section> -->
	

<!-- 
Titel: Der Entwicklungsprozess eines Machine Learning Projekts

Ein Tutorial aus dem Internet zu programmieren oder an einem Kaggle-Wettbewerb teilzunehmen, ist etwas ganz anderes als
die Entwicklung eines maschinellen Lernmodells, das als Teil eines Software-Stacks in Produktion gehen kann. Hierfür
benötigen Sie Fähigkeiten sowohl aus der Welt der Softwareentwicklung als auch aus der Welt der Datenwissenschaft.

ALTERNATIV

Machine Learning Verfahren erfordern für ihr tiefes Verständnis Kenntnisse im Bereich der Linearen Algebra, der Analysis
und der Statistik.
Für den Anwender dieser Verfahren spielt dieses Wissen aber keine wichtige Rolle.
Meist kommen Frameworks wie Scikit-Learn oder TensorFlow und sogar komplett aufgebaute und zum Teil schon trainierte
Neuronale Netzwerke zum Einsatz.
Das verschiebt die Problematik des Machine Learnings in die Richtung des Engineerings.

In diesem Talk beschreiben wir ein Modell für die unterschiedlichen Phasen eines Machine Learning Projekts und
zeigen im technischen Detail, welche Artefakte in welcher Phase entstehen und wie sie in andere Phasen übergehen. Dabei
werden wir Jupyter Notebooks, Jupyter Lab, Colab und Visual Studio Code als Entwicklungsumgebungen verwenden.

M3 Kurzversion:

Ein Tutorial aus dem Internet zu programmieren oder an einem Kaggle-Wettbewerb teilzunehmen, ist etwas ganz anderes als
die Entwicklung eines Machine Learning Modells, das als Teil eines Software-Stacks in Produktion gehen kann. 
Eine der wesentlichen Herausforderungen ist, dass man einerseits interaktiv und explorativ vorgehen möchte, aber gleichzeitig robust und wartbare Software schreiben muss. 
 
In diesem Talk beschreiben wir ein Modell für die unterschiedlichen Phasen eines Machine Learning Projekts und zeigen im technischen Detail, 
welche Artefakte in welcher Phase entstehen und wie diese in andere Phasen übergehen.


Vorkenntnisse:

Entweder eine grundlegende Idee von der Arbeit im Bereich Data Science oder Software-Entwicklung.

Lernziele:

Teilnehmer verstehen die besondere Herausforderung der professionellen Entwicklung einer Machine Learning Modells und dazu einen passenden Ansatz.

M3 Workshop:

Fortgeschritten

Titel: Engineering eines Machine Learning Projekts mit Python

Kurzbeschreibung für M3

Eine praxistaugliche Anwendung mit Techniken des Machine Learnings zu entwickeln ist in erster Linie eine Herausforderung im Bereich des Engineerings 

In diesem Workshop gehen wir gemeinsam durch die unterschiedlichen Phasen eines Machine Learning Projekts, von der Exploration und Validierung eines Machine Learning Ansatzes über
die Professionalisierung zu einem stabilen Stück Software bis in den produktiven Einsatz. Dabei geht es mehr um den Entwicklungsprozess und weniger um die konkret eingesetzte Technik und 
die Bibliotheken.

Längere Version nur angefangen

In der ersten Phase entwickeln wir eine Machine Learning basierte Lösung für ein gegebenes Problem. 
Dabei iterieren wir mit der Hilfe von Notebooks schnell durch unterschiedliche Experimente. Am Ende dieser Phase haben wir unsere Idee (hoffentlich) validiert und können 
mit diesem Ansatz in die nächste Phase übergehen. 

In Phase zwei professionalisieren wir unseren gefundenen Ansatz in Richtung Produktion. 




Vorkenntnisse

Teilnehmer sollten entweder mit den Werkzeugen und dem Vorgehen im Bereich Data Science und/oder als Machine Learning Engineer grundlegende Erfahrung haben. Die Sprache Python ist ebenso Grundlage.
Die Werkzeuge sind von untergeordneter Bedeutung. Kenntnisse im Bereich TensorFlow oder Scikit-Learn, Jupyter Notebooks und Colab erleichtern die Entwicklung jedoch.

Lernziel

In diesem durch praktische Übungen geprägten Workshop wollen wir zusammen die Herausforderungen kennen lernen und meistern, die sich aus dem Ziel "langfristig in Produktion" sein ergeben.

-->
<!-- <section data-markdown class="todo">
	<textarea data-template>
### Shift und Monitoring		

https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html
</textarea>
</section> -->

<!-- <section data-markdown>
	<textarea data-template>

	<img src="img/twitter-tenenholtz-zillow.png" height="400">

	https://twitter.com/marktenenholtz/status/1496107516324835331
</textarea>
</section> -->

<!-- <section data-markdown>
	<textarea data-template>

### Was muss man für ML können?	

<img src='img/role-ml-engineer.png' style="height: 400px">

Da steht nichts von Mathematik oder Verständnis wie ein neuronales Netz funktioniert.

https://boards.greenhouse.io/openai/jobs/4050138004
</textarea>
</section>
 -->

<section data-markdown>
	<textarea data-template>
		### Wer ist Olli

		<div style="display: flex;">
			<div style="flex: 50%;">
				<a href='https://oreilly.de/produkt/machine-learning-kurz-gut-2/'>
				<img src='img/ml-buch-v2.jpg' height="400">
				</a>
			</div>
			<div style="flex: 50%; font-size: x-large;">
				<img src='img/olli-opa.jpeg'>
			</div>
		</div>
		<p>
			<a target="_blank" href="mailto:OliverZeigermann@gmail.com">Oliver Zeigermann</a>:
		Entwickler, Architekt, Berater und Coach für Machine Learning
		</p>    
	</textarea>
</section>

<section data-markdown>
	<textarea data-template>
		### Wer ist Mikio
		<img src='img/mikio-data.jpeg'>

		<a target="_blank" href="mailto:mikiobraun@gmail.com">Mikio Braun</a>:
		Ex-ML Researcher, Architekt, Berater und Mentor für Machine Learning
	</textarea>
</section>

			<!-- <section data-markdown>
				<textarea data-template>
<img src='img/freud-lecturing.png'>					

<small>

https://twitter.com/cedric_p/status/1486743144163155974
</small>

				</textarea>
			</section> -->


			<!-- <section data-markdown>
				<textarea data-template>
### Wieso dieser Talk und wieso so?

* Was kann man schon machen in einem Talk?
* Einblick in meine Welt zwischen ML und Dev
* Möglichst realistisch und anschaulich	
* Skizzen illustrieren die Vorläufigkeit aller dieser Ideen
* Jede SKizze erlebt bei jeder Iteration eine Veränderung oder Verfeinerung 
	</textarea>
			</section> -->



<section data-markdown>
	<textarea data-template>
## Unser Beispiel: Vorhersage von Risiken

* Wir sind CTO einer hochinnovativen Kfz-Versicherungsgesellschaft
* Anders als andere Versicherungsgesellschaften bestimmen wir den Tarif anhand der geschätzen Anzahl von Unfällen pro Kunde
* Zielsetzung: Wie viele Unfälle werden die potenziellen Kunden haben?

<img src='img/pixabay/accident-151668_1280.png' style="height: 230px">
    </textarea>
			</section>

			<section>
				<h3>Klassifizierung basierend auf bekannten Daten</h3>
				<img src="img/insurance-new/train-data.png" height="500px" class="fragment">
			</section>


			<section data-markdown>
				<textarea data-template>
### Vorhersage von Risiken für potenzielle Kunden

<a href='html/calculator.html'>
<img src='img/calculator.png' height="400">
</a>
<p><small>
<a href='html/calculator.html' target="_blank">
https://djcordhose.github.io/ml-resources/html/calculator.html</a></small>
</small></p>
	</textarea>
</section>

			<!-- <section data-markdown>
				<textarea data-template>
### Man muss sein Problem so formulieren, dass es für ML greifbar wird

<img src='img/software-complexity.png'>

<small>
Andrej Karpathy - TRAIN AI 2018 - Building the Software 2.0 Stack

https://vimeo.com/272696002

</small>
				</textarea>
			</section> -->

			<!-- <section data-markdown>
    <textarea data-template>
### Literate Statistical Programming

1. Intent
1. Code
1. Data
1. Results
1. (Interpretation)

_Idee implemented in so called "notebooks"_

<small>https://en.wikipedia.org/wiki/Literate_programming</small>
<br>
<small>https://education.arcus.chop.edu/literate-statistical-programming/</small>

</textarea>
</section> -->

			<section data-markdown style="font-size: x-large;">
				<textarea data-template>
## Schritt \#1 - Live Coding - Notebooks, interaktive Skripte

### Wie fühlt sich Arbeit in Notebooks an?

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/process/1_all.ipynb

</textarea>
			</section>

			<section data-markdown style="font-size: x-large;">
				<textarea data-template>
## Schritt \#2 - Live Coding

### Wir bringen unser Modell in Produktion

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/process/3_serve.ipynb
</textarea>
			</section>

			<section data-markdown>
				<textarea data-template>
## Daten passen prima zu der Vorhersage

<img src='img/insurance-new/insurance-pred.png' class="fragment">

</textarea>
			</section>

			<section data-markdown>
				<textarea data-template>
# Fertig!

</textarea>
			</section>


			<section data-markdown>
				<textarea data-template>
# Oder?

</textarea>
			</section>

<!-- <section data-markdown>
    <textarea data-template>
<img src="img/phasen-fahrsthul.jpg">
</textarea>
</section> -->


			<section data-markdown>
				<textarea data-template>
### Kann man sinnvoll direkt in Produktion gehen?

<img src='img/mikio/process-overview.png' style="height: 500px;">
    </textarea>
			</section>

			<section data-markdown>
				<textarea data-template>
			# Agenda
			
			* Phase I: _Exploration_
			* Phase II: Professionalisierung
			* Phase III: Produktion
			
				</textarea>
			</section>
						
			
			<section data-markdown class="fragments">
			### Phase I: Exploration
			
			in der ersten Phase eines Machine Learning Projekts wird die Anwendungsidee validiert und ein
			funktionsfähiges Modell entwickelt.
			* dabei ist ein schnelles iterieren und ausprobieren von Ideen zentral
			* das Ziel ist *nicht* ein sinnvolles Stück Software
			* Scripting passt hier besser als Programmieren als Ausdruck für die Tätigkeit
			* das Ziel ist eine schnelle Entwicklung
			* Phase I endet entweder mit
			  * einem funktionsfähigen Modell mit dem man in Phase II übergeht oder
			  * dem Verwerfen des Ansatzes
			
			</section>
			

			<section data-markdown>
				<textarea data-template>
### Phase I hinterlässt gern einen Wust an Notebooks

<img src='img/mikio/phase-i-notebooks.png'  style="height: 600px;">

    </textarea>
			</section>

			<section data-markdown class="fragments">
				<textarea data-template>
### Ist ein Wust an Notebooks ein Problem?

* das ist kein Zeichen von einem unprofessionellen Vorgehen
* ergibt sich aus der Arbeitsweise und Zielsetzung
* jeder Experimentator, erprobte ML Ansatz und jede Iteration kann eine neue, komplett entkoppelte Kopie eines Notebooks rechtfertigen
  * "Das Wichtigste in dieser Phase ist die schnelle Iteration" https://twitter.com/marktenenholtz/status/1488134981985583105
  * "Machen Sie ein einfaches Experiment nach dem anderen" https://karpathy.github.io/2019/04/25/recipe/
* natürlich wird dabei teilweise falsch entkoppelt
  * Wir kopieren alles, auch die Teile, die die beiden Notebooks größtenteils unverändert teilen
  * Solange wir aber nicht wissen was die relevant gemeinsamen Teile sind müssen wir damit weiter machen
* welcher Ansatz mehr Liebe verdient wird erst am Ende dieser Phase klar
    </textarea>
			</section>

<!-- <section data-markdown>
    <textarea data-template>
### Warum so viele unterschiedliche Experimente?

### Herausforderungen beim Training neuronaler Netze: 
## Das Training neuronaler Netze scheitert unbemerkt - die mögliche Fehlerfläche ist groß

### "Das Wichtigste in dieser Phase ist die schnelle Iteration." 
https://twitter.com/marktenenholtz/status/1488134981985583105
### "Machen Sie ein einfaches Experiment nach dem anderen" 
https://karpathy.github.io/2019/04/25/recipe/

</textarea>
</section> -->


<section data-markdown class="fragments">
    <textarea data-template>
## Was will man da denn in Produktion bringen?

_ein Modell steht nicht für sich allein_
* es braucht Code für Vor- und Nachbearbeitung
* es ist eingebettet in andere Systeme

_wer will Scripte in Produktion?_
* Notebooks sind interaktive Scripte
* Wie ruft man das denn auf?
* Welches bringen wir in Produktion?
* Wie versionieren wir das? 
* Tests/Dokumentation?
* Debugging/Show References/Refactor/Autocomplete/Quick Fix/etc.?

</textarea>
</section>


			<section data-markdown>
				<textarea data-template>
# Agenda

* Phase I: Exploration
* Phase II: _Professionalisierung_
* Phase III: Produktion

	</textarea>
			</section>

			<!-- <section data-markdown>
				<textarea data-template>
<img src='img/ml-bad.png'>					

<small>

https://twitter.com/DavidSKrueger/status/1487391569028296710
</small>

				</textarea>
			</section> -->

			<section data-markdown class="fragments">
### Phase II: Professionalisierung

in der zweiten Phase wird die skizzierte Lösung in ein langlebiges Projekt umgewandelt

* alle Regeln einer guten Software-Entwicklung gelten von nun an
* Stabilität und Funktionalität wird gewährleistet
* Die Rahmenbedingungen der Produktionsumgebung müssen erfüllt werden
* Art des Deployments, Sprache, Latenz, Speicher, Bandbreite, etc.
* Phase II endet entweder mit
  * reifem Code und Modell mit dem man in Phase III übergeht oder
  * dem iterieren zurück in Phase I mit neu gewonnenen Erkenntnissen oder falls Rahmenbedingungen nicht erfüllt werden

			</section>


<section data-markdown>
	<textarea data-template>
		<img src='img/mikio/process-details.png' style="height: 650px;">
    </textarea>
</section>

			<section data-markdown>
				<textarea data-template>
### Was gehört in Bibliotheken ausgelagert?

* Wir können nicht mit einem Notebook in Produktion gehen
  * also muss alles was wir in Produktion brauchen aus den Notebooks herausgezogen werden
* Bestimmte Teile eines Notebooks haben sich als stabil herausgestellt und sollten nicht bei jeder Kopie entkoppelt werden
* Alles was sich nach Software anfühlt (Klassen, Funktionen, etc.) ist auch Software
  * diese Teile sollten auch wie solche behandelt werden
* Professionalisierung muss gut abhängen
  * erste Version der exrahierten Module ist mit Sicherheit nicht endgültig
  
    </textarea>
			</section>

			<section data-markdown style="font-size: x-large;">
				<textarea data-template>
## Schritt \#3 - Live Coding

### Entscheidende Teile in Bibliotheken auslagern

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/process/2_train.ipynb
</textarea>
			</section>

<section data-markdown>
## Eine Business Metrik ableiten
</section>
		  
<section data-markdown>

Yeah, being good at solving ML problems is great, but in reality you need to be able to make the connection to real customer or business problems, and I‘m not convinced Kaggle trains you well for that.

https://twitter.com/mikiobraun/status/1510628208223215626
	</section>
	
	<section data-markdown>
I have learned over and over again that it is key to formalize the problem in a way that you can evaluate the quality of
a solution using your data. You do this by defining a procedure (I really mean code) that takes a solution for your
problem, and runs it against your data set and measures in a problem specific way how well it works.

https://mikiobraun.wordpress.com/2022/02/08/why-recipes-for-machine-learning-solutions-dont-work/
</section>

<section data-markdown class="fragments">
###	Was sagt Olli dazu

* Ich glaube da nicht dran
* Weil: das kriegt keiner vernünftig hin aus dem Stand eine Business Metrik zu definieren
* Kannste Meeting um Meeting machen ohne Fortschritt
* Ich glaube: man braucht diese Metrik, bekommt die aber erst im Laufe der Zeit
* Erst in der Phase nach den Experimenten
* Und: man weiß nicht, ob die sich überhaupt lohnt, die zu entwickeln, ist ja fast ein Projekt für sich
* Ausnahme: manche Firmen haben ohnehin Metriken für ihre menschlichen Prozesse, die haben einen riesigen Vorteil
</section>

<section data-markdown class="fragments">
###	Und Mikio?

* Ja, ich glaub auch nicht, dass man das hinbekommt, bzw ist es echt schwierig. 
* Aber ich merke auch immer wieder mal, dass Leute denken man baut so ML Lösungen, 
* weil man weiss ja wie man ein Problem löst. 
* Aber zu wissen wie man das evaluieren will ist total essentiell, um das tunen zu können.
* man fängt ja oft mit was doofem wie Accuracy an.
</section>

			<section data-markdown>
				<textarea data-template>
# Agenda

* Phase I: Exploration
* Phase II: Professionalisierung
* _Phase III: Produktion_

	</textarea>
			</section>

			<section data-markdown>
				<textarea data-template>
<img src='img/everybody-gansta.png' style="height: 600px">

<small>

https://twitter.com/karpathy/status/1486215976559398915
</small>

</textarea>
			</section>

			<!-- <section data-markdown>
				<textarea data-template>
<img src='img/twitter-taylor-ml-deployment.png'>

<small>

https://twitter.com/SamuelDataT/status/1488150832742899718
</small>

</textarea>
			</section> -->

			<section data-markdown class="fragments">
### Phase III: Produktion / Betrieb

in der dritten Phase wird die Lösung in Betrieb genommen

* alle Regeln des produktiven Einsatzes von Software gelten auch hier
* Monitoring hat zusätzliche Herausforderungen
  * Natur und Verteilung der Anfragen und auch Vorhersagen muss permanent überwacht werden
* Phase III endet entweder mit
  * der Abschaltung 
    * entweder bald weil nutzlos oder
    * später weil durch neues System ersetzt
  * dem Iterieren zurück in Phase II mit neu gewonnenen Erkenntnissen
  * dem Iterieren zurück in Phase I mit neu gewonnenen Erkenntnissen oder einem Neuansatz (häufig ebenfalls ein Zeichen für einen Fehlschlag)

			</section>

			<section data-markdown class="fragments">
### Technische Umsetzung des Betriebs in Produktion

* haben wir bereits vorhin gesehen
* Ein TensorFlow Graph lässt sich in unterschiedlichsten Szenarien einzusetzen
  * Als Server
     * local
	 * GCP
  * Von C++
  * Von JavaScript
  * Von Java
   
			</section>


			<!-- <section data-markdown>
				### Was ist MLOps?

				_MLOps is a set of practices used to deploy and maintain machine learning models in production._

				In layman terms, MLOps covers everything that comes after model building. After a model is trained and evaluated, it is
ready for end-use. It can then make predictions on new user data entering the system.


				https://towardsdatascience.com/the-mlops-engineer-role-a-gentle-introduction-8d94cdc73904
			</section>

			<section data-markdown class="fragments">
				### Warum MLOps?

				* im akademischen Leben zählt für einen Wettbewerb häufig nur der Score (Güte) des Modells
				* dieser Ansatz hat sich im Bereich des Data Science auch in der Praxis breit gemacht
				* die Praxis ist aber keine Kaggle Competition
				* In-Sample Evaluation (auch wenn wir die vorher abgetrennt haben) sagt nur bedingt etwas für Eignung in
				einer praktsichen Anwendung aus
				* Out-Of-Sample Evaluation häufig erst im produktiven Betrieb möglich (evtl nur mitlaufen lassen)
			</section>
 -->
			<!-- <section data-markdown>
				<textarea data-template>
### Eine ML Lösung hat 2 Artefakte: Code und Modell		

* Beides muss in Prod gebracht werden
* Daten und Modell muss extern gehalten, aber zusammen mit Code versioniert werden
* Modell beschreibt einen Ausschnitt der Realität. Wie finde ich heraus wie gut es das tut uns vor allem für relevante Teile der Welt und was mache ich wenn sich das ändert
* Richtung: Benchmark und Monitoring der Lösung in Produktion
* Prod geht auf Code und Modell Binaries, Modell Graph überall ausführen

</textarea>
			</section>

			<section data-markdown>
				<textarea data-template>
### Nicht aller Code ist für Produktion gedacht		

* Was geht in Produktion
  * Vorhersage
  * Monitoring

* Was geht nicht in Produktion
  * Training
  * Analytics
  * Visualisierung


</textarea>
			</section>

			<section data-markdown class="fragments">
				<textarea data-template>
### Probleme: Selection/Survivor Bias

* Wir können nicht aktiv Daten sammeln, sondern nur von unseren Kunden
* Wir haben keine explizite Kontrolle darüber, wer bei uns versichert werden will und wessen Unfalldaten wir bekommen
* Es gibt aber eine Tendenz dahin, dasss eher Kunden mit guten Konditionen kommen
* Mögliche Lösung: ab und zu risikoreichen Personen gute Angebote machen
* Neues Problem: potentielle Nachvollziehbarkeit

https://en.wikipedia.org/wiki/Survivorship_bias
</textarea>
			</section> -->

			<!-- <section data-markdown class="fragments todo" style="font-size: x-large;">
### Phase 3: Betrieb

* Schwierigkeit:
	* Müssen wir wieder zurück ins Experiment?
	* Wie finden wir heraus, ob unser Modell gut funktioniert?

* Monitoring
	* Alles was man auch sonst monitort
	* Plus Anfragen sammeln und Vorhersagen mitschreiben

* Achtung Bias
	* Wenn wir nur die vermeintlich guten Kunden annehmen, wie können wir dann einen schlechten erkenen?
	* wir haben ja gar keinen oder nur wenige als Kunden
	* Einen gewissen Prozentsatz mit schlechter Hypothese ein sehr gutes Angebot machen

			</section> -->

			<!-- <section data-markdown class="todo">

- Information über Schadensfälle neuer Kunden kommen nur verzögert
- Aber neue Meldungen über Schandensmeldungen kommen permanent
- wie oft neu trainieren?
- mit welchen Daten? Aktualität vs Datenmenge?
- wie schnell ändert sich die Welt? wie schnell die Menschen die bei uns Kunden sein wollen?
- Datensätze schnell statistisch vergleichen mit describe
			</section>
 -->

			<section data-markdown class="fragments">
				<textarea data-template>
### Wir lassen das System ein bisschen in Produktion laufen

Mal sehen wie sich das System macht

- Information über Schadensfälle neuer Kunden kommen nur verzögert
- Aber neue Meldungen über Schandensmeldungen kommen permanent
- Wir haben keine explizite Kontrolle darüber, wer bei uns versichert werden will und wessen Unfalldaten wir bekommen
- Es gibt aber eine Tendenz dahin, dasss eher Kunden mit guten Konditionen kommen

<small>

https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/mlops/3_mlops_shift.ipynb
</small>

</textarea>
			</section>


			<section data-markdown>
				<textarea data-template>

<!-- <img src='img/6monts-later.jpg' height="600px"> -->
<img src='img/2year-later.jpg' height="600px">

</textarea>
			</section>


			<section data-markdown data-transition="none">
				<textarea data-template>
## Ergebnis des Modells nach zwei Jahren

<img src='img/insurance-new/insurance-after-shift.png' class="fragment">

</textarea>
			</section>


			<section data-markdown data-transition="none">
				<textarea data-template>
## Ursprüngliche Daten zum direkten Vergleich

<img src='img/insurance-new/insurance-pred.png'>

</textarea>
			</section>

			<section data-markdown class="fragments">
				<textarea data-template>
### Was ist hier passiert? 

*Die Welt steht nicht still - Model und Welt laufen auseinander, aus 70%  Genauigkeit werden 65%*

* Elektroautos finden weitere Verbreitung
* potente Elektroautos haben allgemein deutlich geringere Höchstgeschwindigkeit 
  * aber super Beschleunigung
* Gute Beschleunigung ist viel eher Ursache für rasante Fahrweise, Unfallwahrscheinlichkeit ist hoch
* Wir haben aber nur Höchstgeschwindigkeit als Daten (seht im Fahrzeugschein), Korrelation war angenommen
* Der Cluster mit jungen, schlechten Fahrern ist nach unten gerutscht
* _Wird nun fälschlich als gut vorhergesagt und werden günstig versichert_
<!-- * Tatsächlich sehen wir aber viele Unfälle -->
<!-- - Faherer vielleicht ein bisschen älter geworden -->
</textarea>
			</section>

			<!-- <section data-markdown>
				<textarea data-template>
### Prozess eines ML-Projekts

<img src='img/sketch/phases.png' style="height: 100%;">    
</textarea>
			</section>


			<section data-markdown>
				<textarea data-template>
### Wieso MLOps oder warum ist ein Modell nie wirklich fertig

_Concept und Data Drift_
- Vorhersagen werden ohne Nachtraining schlechter 
- die Welt entwickelt sich weiter und liefert andere Daten

_Passiert_
- plötzlich (neue oder veränderte Konkurrenten, schwerwiegende Ereignisse) oder
- schleichend (gesellschaftliche Entwicklungen)

unterschiedliche Abschnitte der Daten können unterschiedlich schnell vergammeln

<small>

https://en.wikipedia.org/wiki/Concept_drift
<br>
https://twitter.com/chipro/status/1313921889061015557

</small>
    </textarea>
			</section> -->			

			<section data-markdown class="fragments">
				<textarea data-template>
### Wir gehen zurück in die Phasen I und II

* hier wird wieder in Notebooks gearbeitet
* die Bibliotheken werden inkludiert und bei jeder Änderung neu geladen
* Jupyter Lab bietet eine gemeine Oberfläche für Notebooks und Bibliotheken
* Eine Kombination von Visual Studio Code und Jupyer Notebooks ist ebenso möglich
<!-- * Selbst Colab erlaubt das Arbeiten auf einer Kombination von Notebooks und Bibliotheken
  * Referenz: Module in Colab nutzen: https://colab.research.google.com/drive/1hDUO1-EzMVtVt6snmgrR1I1A36oPp4J9 -->
* Rückker in Phase I muss nicht radikal sein
  * wenn Ansatz vergleichbar kann Phase II so erhalten bleiben
  * neue Ergebnisse fliesen dann iterativ in die Professionalisierung

</textarea>
			</section>

			<section data-markdown class="fragments">
				<textarea data-template>
### Woher weiß man, dass man ein neues Modell in Produktion braucht?

1. Mindestens einmal im Jahr, damit man überhaupt noch weiß wie es geht
1. Wenn die Metrik des Modells nachlässt in Produktion
   1. Dafür braucht man die Ground Truth der Daten aus Produktion
   1. Manchmal bekommt man diese unmittelbar nach der Vorhersage durch die Reaktion eines menschlichen Benutzers
   1. Oft aber auch erst nach nennenswerter Verzögerung 
   1. Manchmal auch nie
1. Wenn sich die Verteilung der Daten der Anfragen deutlich von denen des Trainings unterscheiden 
1. Wenn sich die Verteilung der Vorhersagen deutlich ändern
</textarea>
			</section>


<section data-markdown>
### MLOps versucht diese Praktiken zusammenzufassen

_MLOps is a set of practices used to deploy and maintain machine learning models in production._

In layman terms, MLOps covers everything that comes after model building. After a model is trained and evaluated, it is
ready for end-use. It can then make predictions on new user data entering the system.


https://towardsdatascience.com/the-mlops-engineer-role-a-gentle-introduction-8d94cdc73904
			</section>

<section data-markdown>
    <textarea data-template>
## MLOps mit TFX
_TFX als ein Beispiel für MLOps mit TensorFlow_

<a href='https://www.tensorflow.org/tfx'><img src='img/mlops/tfx-übersicht.jpg' style="height: 400px;"></a>
<small>
https://www.tensorflow.org/tfx
<br>
https://www.tensorflow.org/tfx/guide#tfx_standard_components
<br>
https://github.com/tensorflow/tfx
<br>
https://blog.tensorflow.org/2020/09/brief-history-of-tensorflow-extended-tfx.html
</small>

</textarea>
    </section>

			<!-- <section data-markdown>
				<textarea data-template>
### Referenz: Module in Colab nutzen

https://colab.research.google.com/drive/1hDUO1-EzMVtVt6snmgrR1I1A36oPp4J9
</textarea>
			</section>
 -->
			<section data-markdown>
				<textarea data-template>
## Vielen Dank

### Der Entwicklungsprozess eines Machine-Learning-Projekts

M3 2022, https://www.m3-konferenz.de/veranstaltung-14114-0-der-entwicklungsprozess-eines-machine-learning-projekts.html

Bleibt gern im Kontakt

Oliver Zeigermann

Mikio Braun 

https://www.linkedin.com/in/mikiobraun / [@mikiobraun](https://twitter.com/mikiobraun)


https://www.linkedin.com/in/oliver-zeigermann-34989773/  https://twitter.com/DJCordhose oliver.zeigermann@openknowledge.de


### Diese Folien: https://bit.ly/m3-2022-ml-dev

    </textarea>
			</section>


		</div>
	</div>

	<script src="reveal.js/dist/reveal.js"></script>
	<script src="lib/jquery.js"></script>
	<script>
		const printMode = window.location.search.match(/print-pdf/gi);
		const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
			window.location.hostname.indexOf('127.0.0.1') !== -1;
		const isPresentation = isLocal && !printMode;
		const isPublic = !isPresentation;

		$('.hide').remove();

		if (isPresentation) {
		} else {
			// only applies to public version
			$('.todo').remove();
			$('.preparation').remove();
			$('.local').remove();
		}

		Reveal.addEventListener('ready', function (event) {
			// applies to all versions
			$('code').addClass('line-numbers');

			$('.fragments li').addClass('fragment')

			// make all links open in new tab
			$('a').attr('target', '_blank')

			if (isPresentation) {
				// only applies to presentation version
				Reveal.configure({ controls: false });
			} else {
				// only applies to public version
				$('.fragment').removeClass('fragment');
			}

			// we do not like fragments
			// $('.fragment').removeClass('fragment');

		});

	</script>

	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			controls: true,
			progress: true,
			history: true,
			center: true,
			width: 1100,
			slideNumber: true,
			hideInactiveCursor: false,


			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
		});
	</script>


</body>

</html>
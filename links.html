<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Links to Resources</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <section data-markdown>
                <textarea data-template>
# Structured and commented links to ML resources

    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Dev Workflow                    

#### py module vs Notebook
* Rule of thumb when py when ipynb (too simple): https://twitter.com/eprosenthal/status/1488932302075879425
  * https://twitter.com/rasbt/status/1488969176022667264
    </textarea>
            </section>
            

            <section data-markdown>
                <textarea data-template>
### Foundation Models                    
* AlphaCode
  * https://twitter.com/DeepMind/status/1488907829276725252
    * https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode
  * Performance Evaluation: https://twitter.com/DBahdanau/status/1489009994007674881
  * Competition-Level Code Generation with AlphaCode @DeepMind https://t.co/eKXkGVjiUO  
    * They train an encoder-decoder transformer model to solve @codeforces programming problems and achieve a ranking of top 54.3%. üßµüëá https://t.co/glEZurBAXz
    * https://twitter.com/papers_daily/status/1489158600815792128
* GPT3-Embeddings
  * https://openai.com/blog/introducing-text-and-code-embeddings/
  * Critique, high cost, low performance: https://twitter.com/Nils_Reimers/status/1487014195568775173

    </textarea>
            </section>


            <section data-markdown>
                <textarea data-template>
### Model Validation                    
* https://arxiv.org/abs/1811.12808
  * https://twitter.com/marktenenholtz/status/1482855599817822213
    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Recipes for Training Models
                     
* https://karpathy.github.io/2019/04/25/recipe/
* https://twitter.com/marktenenholtz/status/1488134981985583105    
* Impact of learning rate still amazes me! I would have never expected this graph ü§Ø Few interesting things to know: https://t.co/UG5XKtfYJP (https://twitter.com/borisdayma/status/1489292077313703939?t=3hjj8VWUkJ8-W8Pj19zOkg&s=03) 
</textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### GPUs
                     
* https://twitter.com/marktenenholtz/status/1489222150384848900
* Excellent and unintuitive read on GPUs. The chip doing the compute has tiny amount of memory & is connected to the main memory literally through a straw. Most of the energy goes to data movement too. Many repercussions. E.g. latency better predicted by # activations than # flops
(https://twitter.com/karpathy/status/1503874225475567620?t=VSzdvBMx3J0nhCmCeBVoIA&s=03) 
</textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### GNNs

* Graph neural networks (GNNs) are rapidly advancing progress in ML for complex graph data applications. Let's have a look at some resources to help you learn and keep up-to-date with GNNs ‚Üì https://t.co/0CCZytoXID
(https://twitter.com/omarsar0/status/1490276912601653248?t=lh5yyyK3YsKc5A9pAWQcpw&s=03)
* https://colab.research.google.com/github/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb
* (0/8) Graph theory and GNNs can be scary at first with so many architectures. Here I propose the Maze analogy to help make it more intuitive.

Top 6 strategies for navigating a maze: walking, coloring the way, squeezing through, using a map, destroying walls, or using wings. https://t.co/e4dvFUUEhM
(https://twitter.com/dom_beaini/status/1499019741234704385?t=EKoAP8Cg9-ITAL3J5WGRng&s=03) 
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Generalization of Deep Learning

* https://twitter.com/gautamcgoel/status/1494762029810208772    
* https://twitter.com/roydanroy/status/1494882494990073857 
* https://t.co/XJtCqR81fe "Understanding Generalization through Visualizations" Contains a lovely figure illustrating how SGD is on a magical but perilous journey through a terrifying field of spiky memorized optima, averting each on its quest for high generalization margins https://t.co/AJ9sWxNFF0
(https://twitter.com/nsaphra/status/1496201351877038090?t=A76k7-ZR_ezpeZYa_vWc2w&s=03) 

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
# GPU

* THE AI ACCELERATORS BLOG SERIES In the past few months, I wrote a five-part series on the AI accelerator landscape: motivation, trends, pitfalls, current solutions, and what can we expect to see in the future. Links for all five parts are in the comments üëá (1/6) https://t.co/IqgxqWzS5q
(https://twitter.com/IAmAdiFuchs/status/1472905719213182979?t=Sgmd6ICE3qL6iMJXY8KeCg&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Time Series Data

* üßµIf you want to learn time series analysis, take a look at these great resources created by Konrad Banachewicz ‚¨áÔ∏è 1/N https://t.co/Saby0UzjSG
(https://twitter.com/abhi1thakur/status/1495360495607549952?t=VNLNlWyGM50_gFOhGfhn1Q&s=03) 
  * https://www.kaggle.com/konradb/ts-1-curves
</textarea>
</section>

    <section data-markdown>
        <textarea data-template>
### Tabular Data

https://twitter.com/marktenenholtz/status/1490671701884952576
</textarea>
</section>

<section data-markdown>
    <textarea data-template>

### Selu Activation / Self-Normalizing Networks

https://arxiv.org/abs/1706.02515
https://github.com/bioinf-jku/SNNs
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Deep reinforcement learning keeps nuclear fusion plasma stable 

https://twitter.com/317070/status/1494044406298689539
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Effekt von Mindfulness Apps

https://twitter.com/emollick/status/1494142493805494272
https://www.adviksh.com/files/in_progress/sv_mindfulness.pdf
https://www.brown.edu/research/labs/britton/research/varieties-contemplative-experience

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Metrics

Vladimir Haltakov (@haltakov) twitterte um 7:27 PM on Fr., Feb. 25, 2022:
There are two problems with ROC curves

‚ùå They don't work for imbalanced datasets
‚ùå They don't work for object detection problems

So what do we do to evaluate our machine learning models properly in these cases?

We use a Precision-Recall curve.

Thread üëá

#RepostFriday https://t.co/dm3f2RrpmW
(https://twitter.com/haltakov/status/1497277019134087174?t=jWJikO8Lcw9bLDLf3xtmkw&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Active Learning

Lilian Weng (@lilianweng) twitterte um 6:35 PM on Di., Feb. 22, 2022:
Part 2 of ‚Äúwhat if you don‚Äôt have enough training data‚Äù series on active learning. When the labeling budget is limited or labeling cost is very high, active learning comes handy to select the most valuable samples to label next. https://t.co/Lw13BKLzUl
(https://twitter.com/lilianweng/status/1496176826674475009?t=jDCR0ppBbOkJZCZzGBM5qQ&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Visuals

https://github.com/dair-ai/ml-visuals
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Probabilistic

https://probml.github.io/pml-book/
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Decide on a model architecture

Julien Launay (@slippylolo) twitterte um 2:24 PM on Fr., M√§rz 11, 2022:
üéä At @BigscienceW, after 1 year of experiments, discussions, and developments, we are about to start training our final 176B multilingual model!

ü§î But how exactly did we decide on the final model size, shape, and pretraining duration?

‚¨áÔ∏è A short thread! https://t.co/qtAnCB36I2
(https://twitter.com/slippylolo/status/1502274161326141443?t=OfL-FlFGBnoMNMXMJKxDBA&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Typical effort to react SOTA

Owain Evans (@OwainEvans_UK) twitterte um 9:16 PM on Fr., M√§rz 11, 2022:
How many DeepMind researchers does it take to create a major AI paper?  Over 5 years, team size has grown.
Atari DQN (2015): 19
AlphaGo (2016): 20
AlphaFold2 (2021): 32
Gopher language model (2021): 80
(https://twitter.com/OwainEvans_UK/status/1502377990897999887?t=wualBxug0MEa5P99W076MQ&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Kalman filter

Gabriel Peyr√© (@gabrielpeyre) twitterte um 7:00 AM on So., M√§rz 13, 2022:
Oldies but goldies: R.E. Kalman, A New Approach to Linear Filtering and Prediction Problems, 1960. Kalman filter defines recursively an estimator of the parameters of a Gaussian dynamical process.  The basic method to control navigation systems. https://t.co/Bnv9YNFwAd https://t.co/HRs6mlAx4c
(https://twitter.com/gabrielpeyre/status/1502887178896125952?t=8JmO945JBupXPWvpBoWb4A&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Self-Training

Curious about why self-training with unlabeled data can magically improve a classifier‚Äôs performance? Check out the theoretical explanation in the following blog post: https://t.co/A8VNyobLjh from @ColinWei11, @jhaochenz, and @tengyuma
(https://twitter.com/StanfordAILab/status/1503474138748497925?t=g8tthyr0yoZRHpDwE6zC0g&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Survey, Kaggle

Whoa. 96% of the winning solutions used Python. This is the way.

Interesting tidbit: all winning NLP solutions used transformers. However, most winning computer vision solutions were still  convolutional nets (mostly EffficientNet).
(https://twitter.com/rasbt/status/1503719007819644930?t=s0if9K64UgHW4BT5YrPmag&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Time Series

https://www.kaggle.com/konradb/ts-1-curves

* Exponential Smoothing
* from statsmodels.tsa.holtwinters import ExponentialSmoothing
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Standard CNN architectures

Releasing the revisions and implementations of the following popular & modern Convolutional Neural Networks architectures:

- AlexNet
- VGG
- GoogLeNet
- ResNet
- ResNeXt
- Xception
- DenseNet
- MobileNetV1&2
- EfficientNet
- RegNet
- ConvMixer
- ConvNeXt

https://t.co/Sde02Wut7q
(https://twitter.com/Jeande_d/status/1502989716043444224?t=yQO5DjTv8khKijTw86vb-A&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Gaussian Naive Bayes Classifier

Gaussian Naive Bayes Classifier https://t.co/eZ2bbpDzwV https://t.co/gcwZFH99dR
(https://twitter.com/chrisalbon/status/1511780789695909890?t=BwIp-1ATVSiorqnn3UI0Aw&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Making Sense of model importance

* https://2022.pycon.de/program/9LZTRR/
* https://github.com/glemaitre/pydata_berlin_2022_scikit_learn_tutorial
* https://github.com/glemaitre/pydata_berlin_2022_scikit_learn_tutorial/blob/main/notebooks/plot_linear_model_coefficient_interpretation.ipynb
</textarea>
</section>


</div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>
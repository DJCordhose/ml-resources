<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Links to Resources</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <section data-markdown>
                <textarea data-template>
# Structured and commented links to ML resources

    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Gute Sachen mit Matplotlib

https://github.com/rougier/scientific-visualization-book            
</textarea>
</section>

            <section data-markdown>
                <textarea data-template>
### Convex, Concave, Affine?

* https://dcp.stanford.edu/
* https://github.com/cvxgrp/cvx_short_course
* https://web.stanford.edu/~boyd/papers/cvx_short_course.html
</textarea>
</section>


            <section data-markdown>
                <textarea data-template>
### Missing Data

Data Science Dojo (@DataScienceDojo) twitterte um 8:04 PM on So., Juli 03, 2022:
üí° An illustration of how to handle missing data.
Source: @thedataprof

#BigData #DataScience https://t.co/saAfomCpbU
(https://twitter.com/DataScienceDojo/status/1543656822548086784?t=wNVeTSlVh2ygDfydJgCh-Q&s=03)             
</textarea>
</section>

            <section data-markdown>
                <textarea data-template>
### Grokking

https://twitter.com/awnihannun/status/1542967463100305408
        </textarea>
    </section>
    
            <section data-markdown>
                <textarea data-template>
### Maximum Likelihood

Kristoffer Magnusson (@krstoffr) twitterte um 3:33 PM on Mi., Feb. 12, 2020:
New interactive post: "Understanding Maximum Likelihood"

I try to illustrate the maximum likelihood method. I've also included the likelihood ratio test, Wald test, and Score test.

https://t.co/LlWcgOkw8t https://t.co/z0ngp32efr
(https://twitter.com/krstoffr/status/1227601599238942722?t=v25hKl-fG7fI_1DJWitkMw&s=03) 
</textarea>
</section>


            <section data-markdown>
                <textarea data-template>
### Dev Workflow                    

#### py module vs Notebook
* Rule of thumb when py when ipynb (too simple): https://twitter.com/eprosenthal/status/1488932302075879425
  * https://twitter.com/rasbt/status/1488969176022667264
    </textarea>
            </section>
            

            <section data-markdown>
                <textarea data-template>
### Foundation Models                    
* AlphaCode
  * https://twitter.com/DeepMind/status/1488907829276725252
    * https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode
  * Performance Evaluation: https://twitter.com/DBahdanau/status/1489009994007674881
  * Competition-Level Code Generation with AlphaCode @DeepMind https://t.co/eKXkGVjiUO  
    * They train an encoder-decoder transformer model to solve @codeforces programming problems and achieve a ranking of top 54.3%. üßµüëá https://t.co/glEZurBAXz
    * https://twitter.com/papers_daily/status/1489158600815792128
* GPT3-Embeddings
  * https://openai.com/blog/introducing-text-and-code-embeddings/
  * Critique, high cost, low performance: https://twitter.com/Nils_Reimers/status/1487014195568775173

    </textarea>
            </section>


            <section data-markdown>
                <textarea data-template>
### Model Validation                    
* https://arxiv.org/abs/1811.12808
  * https://twitter.com/marktenenholtz/status/1482855599817822213
    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Recipes for Training Models
                     
* https://karpathy.github.io/2019/04/25/recipe/
* https://twitter.com/marktenenholtz/status/1488134981985583105    
* Impact of learning rate still amazes me! I would have never expected this graph ü§Ø Few interesting things to know: https://t.co/UG5XKtfYJP (https://twitter.com/borisdayma/status/1489292077313703939?t=3hjj8VWUkJ8-W8Pj19zOkg&s=03) 
</textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### GPUs
                     
* https://twitter.com/marktenenholtz/status/1489222150384848900
* Excellent and unintuitive read on GPUs. The chip doing the compute has tiny amount of memory & is connected to the main memory literally through a straw. Most of the energy goes to data movement too. Many repercussions. E.g. latency better predicted by # activations than # flops
(https://twitter.com/karpathy/status/1503874225475567620?t=VSzdvBMx3J0nhCmCeBVoIA&s=03) 
</textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### GNNs

* Graph neural networks (GNNs) are rapidly advancing progress in ML for complex graph data applications. Let's have a look at some resources to help you learn and keep up-to-date with GNNs ‚Üì https://t.co/0CCZytoXID
(https://twitter.com/omarsar0/status/1490276912601653248?t=lh5yyyK3YsKc5A9pAWQcpw&s=03)
* https://colab.research.google.com/github/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb
* (0/8) Graph theory and GNNs can be scary at first with so many architectures. Here I propose the Maze analogy to help make it more intuitive.

Top 6 strategies for navigating a maze: walking, coloring the way, squeezing through, using a map, destroying walls, or using wings. https://t.co/e4dvFUUEhM
(https://twitter.com/dom_beaini/status/1499019741234704385?t=EKoAP8Cg9-ITAL3J5WGRng&s=03) 
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Generalization of Deep Learning

* https://twitter.com/gautamcgoel/status/1494762029810208772    
* https://twitter.com/roydanroy/status/1494882494990073857 
* https://t.co/XJtCqR81fe "Understanding Generalization through Visualizations" Contains a lovely figure illustrating how SGD is on a magical but perilous journey through a terrifying field of spiky memorized optima, averting each on its quest for high generalization margins https://t.co/AJ9sWxNFF0
(https://twitter.com/nsaphra/status/1496201351877038090?t=A76k7-ZR_ezpeZYa_vWc2w&s=03) 

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
# GPU

* THE AI ACCELERATORS BLOG SERIES In the past few months, I wrote a five-part series on the AI accelerator landscape: motivation, trends, pitfalls, current solutions, and what can we expect to see in the future. Links for all five parts are in the comments üëá (1/6) https://t.co/IqgxqWzS5q
(https://twitter.com/IAmAdiFuchs/status/1472905719213182979?t=Sgmd6ICE3qL6iMJXY8KeCg&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Time Series Data

* üßµIf you want to learn time series analysis, take a look at these great resources created by Konrad Banachewicz ‚¨áÔ∏è 1/N https://t.co/Saby0UzjSG
(https://twitter.com/abhi1thakur/status/1495360495607549952?t=VNLNlWyGM50_gFOhGfhn1Q&s=03) 
  * https://www.kaggle.com/konradb/ts-1-curves
</textarea>
</section>

    <section data-markdown>
        <textarea data-template>
### Tabular Data

https://twitter.com/marktenenholtz/status/1490671701884952576
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Tabular Data
Sebastian Raschka (@rasbt) twitterte um 3:34 PM on Sa., Juli 23, 2022:
[6/6] Link to the paper:
"Why do tree-based models still outperform deep learning on tabular data?" https://t.co/qqOGJsfCsN
(https://twitter.com/rasbt/status/1550836767842000897?t=7JypTGSmXnl3wqsAWtUHyQ&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
Francis Bach (@BachFrancis) twitterte um 6:22 PM on Mo., Juli 25, 2022:
Make some noise for SGD‚Äôs proper entrance to the blog! First part: how overparameterization might change the rules of the game.
https://t.co/onb0pQHrbg https://t.co/UCU0RJB7nF
(https://twitter.com/BachFrancis/status/1551603813408280577?t=2DWGMogE8SofHzW5HUDOfA&s=03) 
</textarea>
</section>


<section data-markdown>
    <textarea data-template>

### Selu Activation / Self-Normalizing Networks

https://arxiv.org/abs/1706.02515
https://github.com/bioinf-jku/SNNs
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Deep reinforcement learning keeps nuclear fusion plasma stable 

https://twitter.com/317070/status/1494044406298689539
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Effekt von Mindfulness Apps

https://twitter.com/emollick/status/1494142493805494272
https://www.adviksh.com/files/in_progress/sv_mindfulness.pdf
https://www.brown.edu/research/labs/britton/research/varieties-contemplative-experience

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Metrics

Vladimir Haltakov (@haltakov) twitterte um 7:27 PM on Fr., Feb. 25, 2022:
There are two problems with ROC curves

‚ùå They don't work for imbalanced datasets
‚ùå They don't work for object detection problems

So what do we do to evaluate our machine learning models properly in these cases?

We use a Precision-Recall curve.

Thread üëá

#RepostFriday https://t.co/dm3f2RrpmW
(https://twitter.com/haltakov/status/1497277019134087174?t=jWJikO8Lcw9bLDLf3xtmkw&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Active Learning

Lilian Weng (@lilianweng) twitterte um 6:35 PM on Di., Feb. 22, 2022:
Part 2 of ‚Äúwhat if you don‚Äôt have enough training data‚Äù series on active learning. When the labeling budget is limited or labeling cost is very high, active learning comes handy to select the most valuable samples to label next. https://t.co/Lw13BKLzUl
(https://twitter.com/lilianweng/status/1496176826674475009?t=jDCR0ppBbOkJZCZzGBM5qQ&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Visuals

https://github.com/dair-ai/ml-visuals
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Probabilistic

https://probml.github.io/pml-book/
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Decide on a model architecture

Julien Launay (@slippylolo) twitterte um 2:24 PM on Fr., M√§rz 11, 2022:
üéä At @BigscienceW, after 1 year of experiments, discussions, and developments, we are about to start training our final 176B multilingual model!

ü§î But how exactly did we decide on the final model size, shape, and pretraining duration?

‚¨áÔ∏è A short thread! https://t.co/qtAnCB36I2
(https://twitter.com/slippylolo/status/1502274161326141443?t=OfL-FlFGBnoMNMXMJKxDBA&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Typical effort to react SOTA

Owain Evans (@OwainEvans_UK) twitterte um 9:16 PM on Fr., M√§rz 11, 2022:
How many DeepMind researchers does it take to create a major AI paper?  Over 5 years, team size has grown.
Atari DQN (2015): 19
AlphaGo (2016): 20
AlphaFold2 (2021): 32
Gopher language model (2021): 80
(https://twitter.com/OwainEvans_UK/status/1502377990897999887?t=wualBxug0MEa5P99W076MQ&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Kalman filter

Gabriel Peyr√© (@gabrielpeyre) twitterte um 7:00 AM on So., M√§rz 13, 2022:
Oldies but goldies: R.E. Kalman, A New Approach to Linear Filtering and Prediction Problems, 1960. Kalman filter defines recursively an estimator of the parameters of a Gaussian dynamical process.  The basic method to control navigation systems. https://t.co/Bnv9YNFwAd https://t.co/HRs6mlAx4c
(https://twitter.com/gabrielpeyre/status/1502887178896125952?t=8JmO945JBupXPWvpBoWb4A&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Self-Training

Curious about why self-training with unlabeled data can magically improve a classifier‚Äôs performance? Check out the theoretical explanation in the following blog post: https://t.co/A8VNyobLjh from @ColinWei11, @jhaochenz, and @tengyuma
(https://twitter.com/StanfordAILab/status/1503474138748497925?t=g8tthyr0yoZRHpDwE6zC0g&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Survey, Kaggle

Whoa. 96% of the winning solutions used Python. This is the way.

Interesting tidbit: all winning NLP solutions used transformers. However, most winning computer vision solutions were still  convolutional nets (mostly EffficientNet).
(https://twitter.com/rasbt/status/1503719007819644930?t=s0if9K64UgHW4BT5YrPmag&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Time Series

https://www.kaggle.com/konradb/ts-1-curves

* Exponential Smoothing
* from statsmodels.tsa.holtwinters import ExponentialSmoothing
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Standard CNN architectures

Releasing the revisions and implementations of the following popular & modern Convolutional Neural Networks architectures:

- AlexNet
- VGG
- GoogLeNet
- ResNet
- ResNeXt
- Xception
- DenseNet
- MobileNetV1&2
- EfficientNet
- RegNet
- ConvMixer
- ConvNeXt

https://t.co/Sde02Wut7q
(https://twitter.com/Jeande_d/status/1502989716043444224?t=yQO5DjTv8khKijTw86vb-A&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Gaussian Naive Bayes Classifier

Gaussian Naive Bayes Classifier https://t.co/eZ2bbpDzwV https://t.co/gcwZFH99dR
(https://twitter.com/chrisalbon/status/1511780789695909890?t=BwIp-1ATVSiorqnn3UI0Aw&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Making Sense of model importance

* https://2022.pycon.de/program/9LZTRR/
* https://github.com/glemaitre/pydata_berlin_2022_scikit_learn_tutorial
* https://github.com/glemaitre/pydata_berlin_2022_scikit_learn_tutorial/blob/main/notebooks/plot_linear_model_coefficient_interpretation.ipynb
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Tomographic Imaging

* https://github.com/TomographicImaging/CIL
* http://www.ccpi.ac.uk/CIL
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Label Errors

https://labelerrors.com/
</textarea>
</section>

<section data-markdown>
### Real World Recommender Systems

Interested in understanding what Recommender Systems look like in the real world?  @karlhigley and I have been working with the @NVIDIAAI Merlin team on a pattern representative of most systems.  Check out our blog: https://t.co/97REgYodI0 and let us know what you think!
(https://twitter.com/Even_Oldridge/status/1514664471339298816?t=17rg1QSqK9UMmhM6q9Uivg&s=03) 
</section>

<section data-markdown>
### Reinforcement Learning, academic material

#ReinforcementLearning My course at ASU has been completed. Slides, videolectures, class notes, and the textbook ‚ÄúLessons from AlphaZero for Optimal, Model Predictive, and Adaptive Control‚Äù can be found at https://t.co/9cQy1Y0Srz
(https://twitter.com/DBertsekas/status/1514937280347082759?t=Esik1-rVmka9Hi6VENx3rQ&s=03) 
</section>

<section data-markdown>
### Confidence Intervals
    
Ever wondered how to add confidence intervals to quantify the uncertainty of your machine learning models' performance estimates?
I just put together a hands-on comparison here: https://t.co/CWcHmjqg0w
(https://twitter.com/rasbt/status/1518609957729546240?t=yt2-yyVZdk_s-3j0AlDfqw&s=03) 
</section>

<section data-markdown>
### Data Loading
    
https://towardsdatascience.com/how-to-use-wikipedia-as-a-data-source-3dfea29e6539
</section>

<section data-markdown>
### Building your own sklearn estimator
        
https://scikit-learn.org/stable/developers/develop.html?highlight=estimator%20tags
https://github.com/adrinjalali/talks/tree/master/2022/sklearn-estimator-ODSC
</section>

<section data-markdown>
### Automatic differentiation implemented from scratch
    
https://github.com/osipov/odsc-europe-2022
</section>

<section data-markdown>
### Practical GPU programming in Python

* https://twitter.com/_JacobTomlinson/status/1536971174294454272
  * https://github.com/jacobtomlinson/gpu-python-tutorial
  * https://rapids.ai/

</section>

<section data-markdown>
### Reinforcement Learning

* for transformers: https://twitter.com/svlevine/status/1539320122749267969
* https://mauicv.com/reinforcement-learning/2020/05/24/policy-gradient-methods.html
* We have open sourced our recent algorithms for Unsupervised Environment Design! These algorithms produce adaptive curricula that result in robust RL agents. This codebase includes our implementations of ACCEL, Robust PLR, and PAIRED.

https://t.co/OykmwqdZma
(https://twitter.com/MinqiJiang/status/1542486732192505857?t=vY6KX6GoKbb2hoUYEq5hrg&s=03) 

</section>

<section data-markdown>
### StatQuest!!! - An epic journey through statistics and machine learning

https://statquest.org/
</section>

<section data-markdown>

10 Keras ecosystem packages to check out: a thread.

1. KerasTuner: Hyperparameter tuning for humans.
https://t.co/qkmMkmjLsT
(https://twitter.com/fchollet/status/1548026831969742849?t=xpGqS7uFT-K3nvpMlg4TXw&s=03) 
</section>

<section data-markdown>
### Uncertainty

* Logic and probability: Uncertainty is caused by things unknown
  * Not enough data / confidence in the data (epistemic uncertainty)
  * Not enough information in the data (intrinsic uncertainty)
  * Not knowable / stochastic in nature (aleatoric uncertainty)

* Statistics: Uncertainty is related to error
  * variation (less precise)
  * bias (systematically inaccurate)

</section>


<section data-markdown>
### Razors

The Arena Razor

When faced with two paths, choose the path that puts you in the arena.

It's easy to throw rocks from the sidelines.

It's scary and lonely in the arena‚Äîbut it's where growth happens.

Once you're in the arena, never take advice from people on the sidelines.

https://twitter.com/SahilBloom/status/1548654053953085442
</section>

<section data-markdown>


### Leakage and the Reproducibility Crisis in ML-based Science

We argue that there is a reproducibility crisis in ML-based science. We compile evidence of this crisis across fields,
identify data leakage as a pervasive cause of reproducibility failures, conduct our own reproducibility investigations
using in-depth code-review, and propose a solution.
        
https://reproducible.cs.princeton.edu/
</section>

</div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>
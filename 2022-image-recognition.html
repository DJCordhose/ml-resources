<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Image Recognition with Python</title>

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <!-- <link rel="stylesheet" href="reveal.js/dist/theme/black.css"> -->
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <!-- <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"> -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/zenburn.css">
    <style>
        .right-img {
            margin-left: 10px !important;
            float: right;
            height: 500px;
        }

        .todo:before {
            content: 'TODO: ';
        }

        .todo {
            color: red !important;
        }

        code span.line-number {
            color: lightcoral;
        }

        .reveal pre code {
            max-height: 1000px !important;
        }

        img {
            border: 0 !important;
            box-shadow: 0 0 0 0 !important;
            height: 450px;
        }

        .reveal {
            -ms-touch-action: auto !important;
            touch-action: auto !important;
        }

        .reveal h1,
        .reveal h2,
        .reveal h3,
        .reveal h4 {
            /* letter-spacing: 2px; */
            font-family: 'Calibri', sans-serif;
            /* font-family: 'Times New Roman', Times, serif; */
            /* font-weight: bold; */
            color: black;
            /* font-style: italic; */
            /* letter-spacing: -2px; */
            text-transform: none !important;
        }

        .reveal em {
            font-weight: bold;
        }

        .reveal section img {
            background: none;
        }

        .reveal img.with-border {
            border: 1px solid #586e75 !important;
            box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
        }

        .reveal li {
            margin-bottom: 8px;
        }

        /* For li's that use FontAwesome icons as bullet-point */
        .reveal ul.fa-ul li {
            list-style-type: none;
        }

        .reveal {
            /* font-family: 'Work Sans', 'Calibri'; */
            font-family: 'Calibri';
            color: black !important;
            font-size: xx-large;
        }

        .container {
            display: flex;
        }

        .col,
        col-1 {
            flex: 1;
        }

        .col-2 {
            flex: 2;
        }
    </style>

</head>

<body style="background-color: whitesmoke;">

    <div class="reveal">
        <div class="slides">

            <!-- 

https://2023.pycon.de/blog/call-for-proposals/
https://pycon.it/en/call-for-proposals
90 minutes Pydata Berlin / 2 hours Pydata It

Computer Vision with OpenCV - it doesn't always have to be deep learning

Computer vision, i.e. the task

Don't lightly throw away classic image recognition


In this workshop we will create a detector for a good selfie. How is the overall quality of the image? Is the image tilted? 
Do you have a nice facial expression? The workshop assumes that you have a basic knowledge of Python.  
All hands-on exercises are on Colab notebooks, so all you need is a laptop, a recent version of a Chrome browser, and a Google account.

---

Version mit OpenCV

Image Recognition using OpenCV
---

It does not always have to be deep learning. While deep learning has definitely earned its place, we should not forget,
that classic image processing and recognition techniques can still have their place in your pipeline. OpenCV is one of
the leading libraries in that area and comes with a Python interface.

We will also investigate where classic image processing has reached its end and where deep learning is without
competition. But, as it turns out, this actually a smooth transition and a lot of concepts from low level image
processing are also found in convolutional neural networks.

The purpose of this workshop is to enable the scientific world to use state of the art image recognition techniques
based on the work Oliver has done in industry.

As a participant you should have an interest in the application of image recognition (maybe from video), and a basic
knowledge of Python and its scientific packages. Objective of the workshop is to have an overview of what can be done
with classic image recognition. We will not rush through the topics, but give you enough time to experiment.

Tutorial Description
---

It does not always have to be deep learning. While deep learning has definitely earned its place, we should not forget,
that classic image processing and recognition techniques can still have their place in your pipeline. OpenCV is one of
the leading libraries in that area and comes with a Python interface.

We will also investigate where classic image processing has reached its end and where deep learning is without
competition. But, as it turns out, this actually a smooth transition and a lot of concepts from low level image
processing are also found in convolutional neural networks.

The purpose of this workshop is to enable the scientific world to use state of the art image recognition techniques
based on the work Oliver has done in industry.

As a participant you should have an interest in the application of image recognition (maybe from video), and a basic
knowledge of Python and its scientific packages. Objective of the workshop is to have an overview of what can be done
with classic image recognition. We will not rush through the topics, but give you enough time to experiment.

Outline
---

- Getting started (30 min)
  - Scope of the library
  - Preparing hands-on: Setting it up on Colab or local machine (repo ready to be cloned)
- Basics (30 min)
  - internal structures of images
  - Regions of interest (ROI)
  - filtering and detection
  - hands-on notebook prepared on Colab or on local machine 
- Background removal from video (30 min)
  - hands-on: use prepared or your own static viewport video to remove background (or foreground)
- Finding contours in images and merge them to polygons (30 min)
   - hands-on: based on extracted foreground find contours and connect them to objects
- Drawing bounding boxes (30 min)
  - hands-on: based on polygons of contours draw bounding boxes and extract as ROIs
- Object Tracking (30 min)
  - hands-on: use camshift or overlap of ROIs to track objects
- Path to Deep Learning (60 min)
  - when do we need deep learning
  - from filters to convolutional networks
  - using neural networks to classify ROIs

Oliver is a computer science professional working on industrial projects in the area of computer vision. He is also an
instructor who has written a number of books and is author of the video course "Deep Learning Crash Course" for manning
(https://www.manning.com/livevideo/deep-learning-crash-course). More at https://zeigermann.eu/


# M3 Keynote

### So geht Image Recognition mit Machine Learning

Ich habe aber noch etwas anderes aus einem Kundenprojekt im Bereich
der Bildverarbeitung, von dem ich keider nicht direkt berichten kann.
Ich kann aber coole Hardware  und visuell sehr anschauliche Demos aus
dem Bereich zeigen und einen Überblick über das Thema geben. Wäre das
auch interessant? Meinst du daraus könnte man sogar eine Keynote
machen, weil es alle Ebenen anspricht und gut zeigt was allgemein
möglich ist?

Bei mir weniger Show, man wird eher auch informiert was geht, aber eben durch Demos. Aber keine Folien. 

Themen
- Pose Tracking
- JS
- Kinect
- Teifenmameras

- Teachable Machine als Startpunkt

- Classification
- OD
- Frames in Videos
- Libs

Titel: So geht Bilderkennung mit maschinellem Lernen


In diesem unterhaltsamen Überblick führt Oliver ohne Folien anhand von visuellen Demonstrationen durch die Welt der Bilderkennung. 

Dabei werden Themen wie Klassifikation, Object Detection und Pose Tracking behandelt. Bei den live-Demonstrationen 
wird diskutiert, warum Bias in diesem Bereich eine besondere Bedeutung hat und man dem beikommt. Auch Spezialhardware mit 
besonderen Eigenschaften wird demonstriert.


Workshop Pydata London

Image Recognition with Python

Abstract

Recognizing what is in an image is a common task. Applications range from simple classification to extracting multiple objects even in video. 

Python is the perfect language for doing image recognition. It features both the expressive power of the language as well 
as the comprehensive and fast libraries. On one hand we will use OpenCV for classic image processing
and on the other hand we have TensorFlow with its Keras API for the machine learning to do pattern matching.

In this hands-on workshop you will learn when to use which library and how to use it. The workshop assumes that you have a basic knowledge of Python.  
All hands-on exercises are on Colab notebooks, so all you need is a laptop, a recent version of a Chrome browser, and a Google account.

Description

This workshop is split into two parts of approx. 45 minutes each. Each part has a well prepared hands-on exercise and a short lecture.

The first part covers classic image processing with OpenCV. 
We will use it to extract objects from complex images and remove noise and other artefacts. 

In the second part we train a classifier using the extracted objects and make it generalize to previously unseen objects. 
For this part we will use standard convolutional neural network architectures provided by the Keras API on top of TensorFlow. 
That means we do not go into the details of the network architecture, but rather how to use it, what options you have, and how to know if you are doing well. 

---

ODSC 

"Image Recognition with OpenCV and TensorFlow" as an in-person Half Day Hands-on Training (3.5 hours)

Session outline (module/lesson wise)

- Getting started (30 min)
  - introduction to image recognition
  - scope of the libraries
  - preparing hands-on: setting it up on Colab or local machine (repo ready to be cloned)
- Classic Image Processing with OpenCV (60 min)
  - internal structures of images
  - regions of interest (ROI)
  - filtering and detection
  - hands-on: detect and extract ROIs from images  
- Deep Learning using TensorFlow (90 min)
  - when do we need deep learning
  - from filters to convolutional networks
  - hands-on: understanding convolutional neural networks
  - what architecture to use
  - how to know if we are fitting the right parts
  - hands-on: using neural networks to classify ROIs
- Closing (30 min)
  - wrap up
  - what else is there? from Transformers to DALL-E
  - open questions

Background Knowledge Needed 

Solid understanding of Python and Notebooks, basic understanding of TensorFlow is helpful.

---

ML Summit 2022, Berlin
Half Day Hands-on Workshop

Image Recognition with OpenCV and TensorFlow

Recognizing what is in an image is a common task. Applications range from simple classification to extracting multiple objects even in video. 

In the Python world there are two standard libraries for this. On one hand there is OpenCV for classic image processing
and on the other hand we have TensorFlow with its Keras API for the machine learning to do pattern matching.

In this hands-on workshop you will learn when to use which library and how to use it. 
All hands-on exercises are on Colab notebooks, so all you need is a laptop, a recent version of a Chrome browser, and a Google account.

Session outline

- Getting started (30 min)
  - introduction to image recognition
  - scope of the libraries
  - preparing hands-on: setting it up on Colab or local machine (repo ready to be cloned)
- Classic Image Processing with OpenCV (60 min)
  - internal structures of images
  - regions of interest (ROI)
  - filtering and detection
  - hands-on: detect and extract ROIs from images  
- Deep Learning using TensorFlow (90 min)
  - when do we need deep learning
  - from filters to convolutional networks
  - hands-on: understanding convolutional neural networks
  - what architecture to use
  - how to know if we are fitting the right parts
  - hands-on: using neural networks to classify ROIs
- Closing (30 min)
  - wrap up
  - what else is there? from Transformers to DALL-E
  - open questions

Background Knowledge Needed 

Solid understanding of Python and Notebooks, basic understanding of TensorFlow is helpful.


---

Stand der Kunst in der Bilderkennung

Bilderkennung ist die Paradedisziplin des Maschinellen Lernens. Gerade in diesem Bereich sind mit künstlichen Neuralen
Netzwerken Erkennungsraten und eine Robustheit möglich, an die mit klassischen Verfahren nicht zu denken war. Allerdings
sind traditionelle Ansätze in manchen Bereichen als Alternative oder in Kombination mit Neuronalen Netzen immer noch
sinnvoll.

In diesem Vortrag führe ich daher durch die folgenden Themen:

1. Traditionelle Ansätze

Was sind diese Ansätze? Wo liegt deren Stärke und wo sind die Grenzen?

2. Neuronale Netzwerke

Wann sind diese sinnvoll und in welcher Architektur? Was braucht man, um sie zu trainieren?

3. Was kommt als nächstes?

Es gibt neuere Ansätze, die in der praktischen Anwendung bisher nicht erprobt sind, aber Potential haben, in der Zukunft
eine größere Rolle zu spielen. Dazu gehören Ansätze auf Basis von Transformern und Systeme, die realitätsnahe Bilder
erzeugen können wie GANs und DALLE-2.


---

Computer Vision: Past, Present and Future

Computer Vision is the parade discipline of machine learning. Artificial neural networks can achieve
recognition rates and robustness that were unthinkable with classical methods. However,
traditional approaches are still useful in some areas as an alternative or in combination with neural networks.

In this talk I take you through the following topics:

1. traditional approaches: What are these approaches non-ML approaches? What is their strength and what are their limitations? When should you still use them?

2. neural networks: When are they useful and in what architecture? What does it take to train them? How to know if their training is successful?

3. what's next: Newer approaches that have not yet been tested in practical applications, but have potential to play a larger role in the future.

-->

<section data-markdown class="todo">
    <textarea data-template>
### Faces Notebooks

Offizielle Kopie für MLCon 2022 Berlin, von Tim W. angepasst: http://bit.ly/mlcon-2022-cv
Meine Kopie vor der Anpassung: https://colab.research.google.com/drive/1EhP2HQgUefdbDIUhG_ft9LYtaWFDl6OL?hl=en
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
Niels Rogge (@NielsRogge) twitterte um 0:25 PM on Fr., Aug. 12, 2022:
H/t to @jeremyphoward for recommending the LeViT series in terms of speed/accuracy trade-off for image classification, based on his plot:

Check below how @huggingface Optimum can be used to fuse its layers and export to ONNX 🚀 https://t.co/WAcEyIU1jy
(https://twitter.com/NielsRogge/status/1558036923138162688?t=kEXaTWRxSuvz5amWhUnh9A&s=03)         
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
Anwendungen

- https://pyimagesearch.com/2023/01/02/computer-vision-and-deep-learning-for-healthcare/
- Blossom – Plant care companion (@BlossomPlant) twitterte um 11:00 PM on Do., Okt. 13, 2022:
How not to kill a plant 📲🌿
(https://twitter.com/BlossomPlant/status/1580664680430837761?t=DQ_JmwA-lgp62kJeRfB4ZQ&s=03) 
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
## Ablauf

Teil 1:
- https://scikit-image.org/
- https://docs.opencv.org/4.6.0/

Teil 2
- Supervised CNN
- Image Anaomalie Detection
  - Beispiel mit Screenshots zeigen

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Beispiel für den Einsatz einer Tiefenkamera

https://twitter.com/pathak2206/status/1540357312703090695
</textarea>
</section>

            <section data-markdown>
                <textarea data-template>
# Image Recognition with Python

Oliver Zeigermann

    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### What can we expect from a ML based system?

https://twitter.com/FredSchultz35/status/1502777661495685127
</textarea>
</section>

            <section data-markdown>
                <textarea data-template>
### Morphologische Operationen, Opening, Closing

https://www.cg.tuwien.ac.at/courses/EinfVisComp/Skriptum/SS14/EVC-18%20Morphologische%20Operationen.pdf
http://kos.informatik.uni-osnabrueck.de/download/stefan_masterthesis.pdf
* 5.4 auch Momente

        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Morphologische Operationen, Opening, Closing

* How would we know this is the main object: Opening 
* How to track it? Meanshift

<img src='img/sketch/object_tracking.png'>

</textarea>
</section>

            <section data-markdown>
                <textarea data-template>
### Abstract                    
- Our focus will be on applications, so we will not go into how things work internally, but rather how to make use of them.
- use prebuilt and pretrained networks for image recognition and object detection
- Applications for Autorencoder for Images
  - Denoising
  - Outlier/Error Detection
  - Visualization
  - Extract Embeddings

    </textarea>
            </section>


            <section data-markdown>
                <textarea data-template>
### Notebooks
- OpenCV: https://github.com/DJCordhose/object-tracking-playground
- 

    </textarea>
            </section>

            <section data-markdown class="todo">
                <textarea data-template>

### Facial Recognition, Dlib
        </textarea>
    </section>

            <section data-markdown>
                <textarea data-template>
# Was geht sonst noch?                    
                </textarea>
            </section>


            <section data-markdown>
                <textarea data-template>
# Kinect

<img src="img/image-recognition/kinect.jpg">
<img src="img/image-recognition/setup-kinect.jpg">
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
### Übergang von 2d auf 3d und Tiefenkameras                    

            Computer vision research feels a bit stagnating in a local minimum of 2D texture recognition on ImageNet, COCO etc. This is great but only step 1. Unlocking further progress needs new framework:
            1) the data source has to become diverse videos, not individual frames from internet
            (https://twitter.com/karpathy/status/1491452689825165314?t=a3kTGU5U0jk8clZKi12lyA&s=03) 
        </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
    
    Andrej Karpathy (@karpathy) twitterte um 6:16 AM on Do., Feb. 17, 2022:
    Is simulation the dark horse of 99% of the
training FLOPS in future "foundation models" of computer vision?
    (https://twitter.com/karpathy/status/1494178962422984706?t=dsqu5ZfAbJ1L3ZrozJbTyQ&s=03) 
</textarea>
</section>



<section data-markdown>
    <textarea data-template>

Ronnie Clark (@ronnieclark__) twitterte um 6:04 PM on Di., Feb. 15, 2022:
After a long review+revision period (~2 years), our paper on Orientation Keypoints will appear in IEEE TPAMI! We introduce "virtual" markers placed around bones to accurately estimate body pose.  (1/6)

Project page: https://t.co/5j1qA7Oz8w https://t.co/6gR8ofL4kE
(https://twitter.com/ronnieclark__/status/1493632232669470725?t=ypeO9dRSe-9u-LspdRhEDA&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>

    Kinect
    - https://unboundvr.de/zakelijk/index.php/microsoft-azure-kinect-dk
    - https://unboundvr.de/zakelijk/index.php/microsoft-azure-kinect-blog
    
    3D Scanning
    - Flowchart: https://twitter.com/ntschk/status/1491268338814959617
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### OpenCV
        
https://github.com/opencv/opencv_contrib
https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Spatial Transformer Networks Using TensorFlow - PyImageSearch

https://pyimagesearch.com/2022/05/23/spatial-transformer-networks-using-tensorflow/
</textarea>
</section>

<section data-markdown>
    <textarea data-template>

Robust-ResNet. 3 Key ideas to make CNNs more robust:
1) patchifying input images similar to ViTs;
2) increasing kernel size;
3) reducing activation layers & norm layers similar to ConvNext.
Paper: https://t.co/R2WissH5W4
Code: https://t.co/9K2Pz50SjQ https://t.co/OuQLk3P0fQ
(https://twitter.com/rasbt/status/1535602552527630336?t=igccTJpyEezxnZVus2ukhA&s=03) 
</textarea>
</section>

<section data-markdown>
    <textarea data-template>

Lilian Weng (@lilianweng) twitterte um 6:59 AM on Di., Juni 14, 2022:
My new post looks into various methods on how to extend a pre-trained foundation language model to be capable of consuming visual signals; in other words, transform a pretrained LM into a VLM to resolve vision language tasks.

https://t.co/STAhwQYnJr
(https://twitter.com/lilianweng/status/1536573975098056704?t=HOoVMx8nUnUSx6FBlUG8LA&s=03) 
</textarea>
</section>

<section data-markdown>
### Wie funktioniert DALLE?

https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--VmlldzoyMDE4NDAy
</section>

        </div>
    </div>


    <script src="reveal.js/dist/reveal.js"></script>
    <script src="lib/jquery.js"></script>

    <script>
        const printMode = window.location.search.match(/print-pdf/gi);
        const isLocal = window.location.hostname.indexOf('localhost') !== -1 ||
            window.location.hostname.indexOf('127.0.0.1') !== -1;
        const isPresentation = isLocal && !printMode;
        const isPublic = !isPresentation;

        $('.hide').remove();

        if (isPresentation) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }

        Reveal.addEventListener('ready', function (event) {
            // applies to all versions
            $('code').addClass('line-numbers');

            $('.fragments li').addClass('fragment')

            // make all links open in new tab
            $('a').attr('target', '_blank')

            if (isPresentation) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }

            // we do not like fragments
            // $('.fragment').removeClass('fragment');

        });

    </script>

    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            history: true,
            center: true,
            width: 1100,
            slideNumber: true,
            hideInactiveCursor: false,


            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
        });
    </script>


</body>

</html>